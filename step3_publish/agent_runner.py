import random
import sys
import os
import time
import json
from datetime import datetime

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from agents.publisher import PublisherAgent
from shared.google_client import GoogleSheetClient
from shared import config
from shared import stats


def load_publish_config():
    """åŠ è½½å‘å¸ƒé…ç½® (ä¼˜å…ˆç¯å¢ƒå˜é‡ï¼Œå…¶æ¬¡æœ¬åœ°æ–‡ä»¶)"""
    # 1. å°è¯•ä»ç¯å¢ƒå˜é‡åŠ è½½ (ç”¨äº GitHub Actions Secret)
    config_json = os.getenv("PUBLISH_CONFIG_JSON")
    if config_json:
        try:
            print("ğŸ” è¯»å–ç¯å¢ƒå˜é‡é…ç½®: PUBLISH_CONFIG_JSON")
            return json.loads(config_json)
        except json.JSONDecodeError as e:
            print(f"âš ï¸ è§£æç¯å¢ƒå˜é‡é…ç½®å¤±è´¥: {e}")
    
    # 2. å°è¯•ä»æ–‡ä»¶åŠ è½½
    if os.path.exists(config.PUBLISH_CONFIG_FILE):
        try:
            with open(config.PUBLISH_CONFIG_FILE, 'r', encoding='utf-8') as f:
                print(f"ğŸ“– è¯»å–æœ¬åœ°é…ç½®æ–‡ä»¶: {config.PUBLISH_CONFIG_FILE}")
                return json.load(f)
        except Exception as e:
            print(f"âš ï¸ è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            
    print(f"âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆé…ç½®")
    return None


def run():
    print("\n" + "=" * 50)
    print("ğŸ¤– å¯åŠ¨ Agentic Workflow (Step 3: Publishing)")
    print("=" * 50 + "\n")
    
    # åŠ è½½é…ç½®è·å–è´¦å·ä¿¡æ¯
    publish_config = load_publish_config()
    accounts = publish_config.get("accounts", []) if publish_config else []
    
    # å‡†å¤‡è´¦å·åˆ—è¡¨ (ç”¨äºè½®æ¢)
    active_accounts = []
    if accounts:
        active_accounts = accounts
        print(f"ğŸ‘¥ åŠ è½½äº† {len(active_accounts)} ä¸ªå‘å¸ƒè´¦å· (å¯ç”¨è½®æ¢æ¨¡å¼)")
    else:
        # Fallback to defaults or single env var
        default_user = config.WELLCMS_USERNAME
        default_pass = config.WELLCMS_PASSWORD
        if default_user:
             active_accounts.append({"username": default_user, "password": default_pass})
             print(f"ğŸ‘¤ åŠ è½½é»˜è®¤è´¦å·: {default_user}")
        else:
             print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•è´¦å·é…ç½®")

    client = GoogleSheetClient()
    
    total_success = 0
    total_fail = 0
    
    # 1. è·å–å¾…å‘å¸ƒæ–‡ç«  (Status='Pending')
    print("ğŸ” [System] æ­£åœ¨æ‰«æå¾…å‘å¸ƒæ–‡ç« ...")
    # é™åˆ¶æ ¹æ® Config
    # [Safe Drip Strategy]
    # 30åˆ†é’Ÿä¸€æ¬¡ï¼Œæ¯æ¬¡éšæœºå‘ 1 æˆ– 2 ç¯‡
    # æ¨¡æ‹ŸçœŸäººè¿™ç§"æƒ³èµ·æ¥å°±å‘ä¸€ç¯‡"çš„è¡Œä¸º
    limit = random.randint(1, 2)
        
    print(f"âš™ï¸  [Drip Mode] æœ¬æ¬¡éšæœºå‘å¸ƒ: {limit} ç¯‡")
    
    pending_records = client.fetch_records_by_status(status=config.STATUS_PENDING, limit=limit)
    
    print(f"ğŸ“‹ å‘ç° {len(pending_records)} ç¯‡å¾…å‘å¸ƒæ–‡ç« ")
    
    
    for idx, record in enumerate(pending_records):
        print(f"\n--- [{idx + 1}/{len(pending_records)}] å‘å¸ƒ: {record.get('Title', '')[:30]}... ---")
        
        # [Idempotency Check] é˜²æ­¢é‡å¤å‘å¸ƒ
        # å¦‚æœçŠ¶æ€æ˜¯ Pending ä½†å·²ç»æœ‰ URLï¼Œè¯´æ˜ä¸Šæ¬¡å‘å¸ƒæˆåŠŸä½†çŠ¶æ€æ›´æ–°å¤±è´¥
        # [Idempotency Check] é˜²æ­¢é‡å¤å‘å¸ƒï¼Œä½†éœ€å¤„ç†é‡ç”Ÿæˆçš„æƒ…å†µ
        # å¦‚æœçŠ¶æ€æ˜¯ Pending ä½†å·²ç»æœ‰ URL:
        # 1. å¦‚æœ GenTime > PubTime -> è¯´æ˜æ˜¯é‡ç”Ÿæˆçš„æ–°æ–‡ç« ï¼Œæ—§ URL æ˜¯è¿‡æœŸçš„ï¼Œåº”è¯¥é‡æ–°å‘å¸ƒã€‚
        # 2. å¦‚æœ GenTime < PubTime -> è¯´æ˜æ˜¯çŠ¶æ€å›æ»šäº†ï¼ŒURL æ˜¯æœ‰æ•ˆçš„ï¼Œåº”è¯¥æ¢å¤ä¸º Publishedã€‚
        existing_url = record.get('URL', '').strip()
        
        if existing_url and existing_url.startswith('http'):
            gen_time_str = record.get('ç”Ÿæˆæ—¶é—´', '2000-01-01 00:00:00')
            pub_time_str = record.get('å‘å¸ƒæ—¶é—´', '2099-12-31 23:59:59') # é»˜è®¤ä¸ºæœªæ¥ï¼Œé˜²æ­¢è¯¯åˆ¤
            
            try:
                gen_time = datetime.strptime(gen_time_str, "%Y-%m-%d %H:%M:%S")
                # æœ‰äº›è®°å½•å¯èƒ½æ²¡æœ‰å‘å¸ƒæ—¶é—´ï¼Œå¦‚æœä¸ºç©ºï¼Œåˆ™è®¤ä¸ºæ˜¯ 1970
                if not record.get('å‘å¸ƒæ—¶é—´'):
                    pub_time = datetime.min
                else:
                    pub_time = datetime.strptime(pub_time_str, "%Y-%m-%d %H:%M:%S")
            except:
                # è§£æå¤±è´¥ï¼Œä¿å®ˆèµ·è§è®¤ä¸ºæ˜¯ Stale
                gen_time = datetime.max
                pub_time = datetime.min

            if gen_time > pub_time:
                print(f"   ğŸ”„ [Stale Check] æ£€æµ‹åˆ°å†…å®¹å·²é‡ç”Ÿæˆ (Gen: {gen_time_str} > Pub: {pub_time_str})")
                print(f"   ğŸ—‘ï¸ å¿½ç•¥æ—§ URLï¼Œæ‰§è¡Œé‡æ–°å‘å¸ƒ...")
                # ä¸ continueï¼Œç»§ç»­å¾€ä¸‹æ‰§è¡Œå‘å¸ƒé€»è¾‘
            else:
                print(f"   âš ï¸ æ£€æµ‹åˆ°è¯¥æ–‡ç« å·²æœ‰ URL ({existing_url}) ä¸”æœªé‡ç”Ÿæˆã€‚")
                print(f"   ğŸ”„ æ­£åœ¨ä¿®å¤çŠ¶æ€ä¸º Published...")
                
                # ä¿®å¤çŠ¶æ€
                client.update_record(record['record_id'], {
                    "Status": config.STATUS_PUBLISHED
                })
                
                # åŒæ—¶ä¹Ÿç¡®ä¿å†™å…¥ asset
                article_data_fix = {
                    "title": record.get('Title'),
                    "url": existing_url,
                    "keywords": record.get('å…³é”®è¯'),
                    "category_id": config.CATEGORY_MAP.get(str(record.get('å¤§é¡¹åˆ†ç±»', '')).strip(), "1"),
                    "summary": record.get('æ‘˜è¦')
                }
                _record_to_assets(article_data_fix, existing_url)
                
                print(f"   âœ… çŠ¶æ€ä¿®å¤å®Œæˆï¼Œè·³è¿‡æœ¬æ¬¡é‡å¤å‘å¸ƒã€‚")
                continue
            
        # [Data Integrity] å‘å¸ƒå‰å¼ºæ ¡éªŒ
        title_chk = record.get('Title', '').strip()
        content_chk = record.get('HTML_Content', '').strip()
        
        if not title_chk or len(content_chk) < 50:
            print(f"   ğŸ›‘ æ£€æµ‹åˆ°æ— æ•ˆå†…å®¹ (Title: {bool(title_chk)}, Content Len: {len(content_chk)})")
            print(f"   ğŸ”„ æ­£åœ¨å°†çŠ¶æ€é‡ç½®ä¸º Ready ä»¥ä¾¿é‡æ–°ç”Ÿæˆ...")
            client.update_record(record['record_id'], {"Status": config.STATUS_READY})
            continue

        # è½¬æ¢ä¸º Skill éœ€è¦çš„æ ¼å¼
        article_data = {
            "title": record.get('Title'),
            "html_content": record.get('HTML_Content'),
            "category_id": config.CATEGORY_MAP.get(str(record.get('å¤§é¡¹åˆ†ç±»', '')).strip(), "1"),
            "summary": record.get('æ‘˜è¦'),
            "keywords": record.get('å…³é”®è¯'),
            "description": record.get('æè¿°'),
            "tags": record.get('Tags')
        }
        
        # 2. Agent å‘å¸ƒ (è´¦å·è½®æ¢)
        current_account = {}
        if active_accounts:
            current_account = random.choice(active_accounts)
            
        cur_user = current_account.get("username")
        cur_pass = current_account.get("password")
        
        print(f"   ğŸ‘¤ [Account] æœ¬æ¬¡ä½¿ç”¨è´¦å·: {cur_user}")
        
        # å®ä¾‹åŒ– Agent (æ¯æ¬¡ç‹¬ç«‹å®ä¾‹åŒ–ä»¥ç¡®ä¿ Session éš”ç¦»)
        agent = PublisherAgent(username=cur_user, password=cur_pass)
        published_url = agent.publish_article(article_data)
        
        if published_url:
            # 3. System Update Feishu
            client.update_record(record['record_id'], {
                "Status": config.STATUS_PUBLISHED,
                "URL": published_url,
                "å‘å¸ƒæ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            })
            print(f"   ğŸ’¾ [System] é£ä¹¦çŠ¶æ€å·²æ›´æ–°ä¸º Published")
            
            # 4. Asset Write-back (SEO Closed Loop)
            _record_to_assets(article_data, published_url)
            
            total_success += 1
            stats.record_published()
        else:
            total_fail += 1
            stats.record_failed()
        
        # Random Interval
        if idx < len(pending_records) - 1:
            # Optimization: speed up for testing (5-15s)
            wait_time = random.uniform(5, 15)
            print(f"   â³ ç­‰å¾… {wait_time:.1f} ç§’...")
            time.sleep(wait_time)

    # å‘é€é£ä¹¦é€šçŸ¥
    if total_success > 0 or total_fail > 0:
        notify_content = f"**å‘å¸ƒç»“æœ**\n- âœ… æˆåŠŸ: {total_success} ç¯‡\n- âŒ å¤±è´¥: {total_fail} ç¯‡\n- â° æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M')}\n\n{stats.get_summary()}"
        client.send_notification(
            title="ğŸ“¤ CMS å‘å¸ƒä»»åŠ¡å®Œæˆ",
            content=notify_content
        )
        print(f"ğŸ“¢ å·²å‘é€é£ä¹¦é€šçŸ¥ (æˆåŠŸ: {total_success}, å¤±è´¥: {total_fail})")

def _record_to_assets(article, url):
    """
    å°†å·²å‘å¸ƒçš„æ–‡ç« è®°å½•åˆ°æœ¬åœ°èµ„äº§åº“ï¼Œç”¨äº SEO å†…é“¾
    """
    import json
    BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    ASSETS_FILE = os.path.join(BASE_DIR, "published_assets.json")
    
    # æ„é€ æ–°è®°å½•
    new_record = {
        "title": article.get("title"),
        "url": url,
        "keywords": article.get("keywords"),
        "category_id": article.get("category_id"),
        "summary": article.get("summary"),
        "published_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }
    
    try:
        data = []
        if os.path.exists(ASSETS_FILE):
            with open(ASSETS_FILE, 'r', encoding='utf-8') as f:
                try:
                    data = json.load(f)
                except:
                    data = []
        
        # ç®€å•å»é‡ (æŒ‰ URL)
        existing_idx = next((i for i, item in enumerate(data) if item.get("url") == url), -1)
        if existing_idx >= 0:
            data[existing_idx] = new_record
        else:
            data.append(new_record)
            
        with open(ASSETS_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
            
        print(f"   ğŸ“š [SEO] å·²æ”¶å½•è‡³èµ„äº§åº“ ({len(data)} ç¯‡)")
        
    except Exception as e:
        print(f"   âš ï¸ èµ„äº§åº“å†™å…¥å¤±è´¥: {e}")

if __name__ == "__main__":
    run()
