import sys
import os
import time
from datetime import datetime

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from agents.publisher import PublisherAgent
from shared.feishu_client import FeishuClient
from shared import config
from shared import stats

def run():
    print("\n" + "=" * 50)
    print("ğŸ¤– å¯åŠ¨ Agentic Workflow (Step 3: Publishing)")
    print("=" * 50 + "\n")
    
    agent = PublisherAgent()
    client = FeishuClient()
    
    total_success = 0
    total_fail = 0
    
    # 1. è·å–å¾…å‘å¸ƒæ–‡ç«  (Status='Pending')
    print("ğŸ” [System] æ­£åœ¨æ‰«æå¾…å‘å¸ƒæ–‡ç« ...")
    # é™åˆ¶æ ¹æ® Config
    limit = config.MAX_PUBLISH_PER_CATEGORY
    print(f"âš™ï¸  å‘å¸ƒä¸Šé™: {limit} ç¯‡")
    
    pending_records = client.fetch_records_by_status(status=config.STATUS_PENDING, limit=limit)
    
    print(f"ğŸ“‹ å‘ç° {len(pending_records)} ç¯‡å¾…å‘å¸ƒæ–‡ç« ")
    
    import random
    
    for idx, record in enumerate(pending_records):
        print(f"\n--- [{idx + 1}/{len(pending_records)}] å‘å¸ƒ: {record.get('title', '')[:30]}... ---")
        
        # è½¬æ¢ä¸º Skill éœ€è¦çš„æ ¼å¼
        article_data = {
            "title": record.get('title'),
            "html_content": record.get('html_content'),
            "category_id": config.CATEGORY_MAP.get(record.get('category'), "1"),
            "summary": record.get('summary'),
            "keywords": record.get('keywords'),
            "description": record.get('description'),
            "tags": record.get('tags')
        }
        
        # 2. Agent å‘å¸ƒ
        published_url = agent.publish_article(article_data)
        
        if published_url:
            # 3. System Update Feishu
            client.update_record(record['record_id'], {
                "Status": config.STATUS_PUBLISHED,
                "URL": published_url,
                "å‘å¸ƒæ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            })
            print(f"   ğŸ’¾ [System] é£ä¹¦çŠ¶æ€å·²æ›´æ–°ä¸º Published")
            
            # 4. Asset Write-back (SEO Closed Loop)
            _record_to_assets(article_data, published_url)
            
            total_success += 1
            stats.record_published()
        else:
            total_fail += 1
            stats.record_failed()
        
        # Random Interval
        if idx < len(pending_records) - 1:
            # Optimization: 60-120s for SEO safety
            wait_time = random.uniform(60, 120)
            print(f"   â³ ç­‰å¾… {wait_time:.1f} ç§’...")
            time.sleep(wait_time)

    # å‘é€é£ä¹¦é€šçŸ¥
    if total_success > 0 or total_fail > 0:
        notify_content = f"**å‘å¸ƒç»“æœ**\n- âœ… æˆåŠŸ: {total_success} ç¯‡\n- âŒ å¤±è´¥: {total_fail} ç¯‡\n- â° æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M')}\n\n{stats.get_summary()}"
        client.send_notification(
            title="ğŸ“¤ CMS å‘å¸ƒä»»åŠ¡å®Œæˆ",
            content=notify_content
        )
        print(f"ğŸ“¢ å·²å‘é€é£ä¹¦é€šçŸ¥ (æˆåŠŸ: {total_success}, å¤±è´¥: {total_fail})")

def _record_to_assets(article, url):
    """
    å°†å·²å‘å¸ƒçš„æ–‡ç« è®°å½•åˆ°æœ¬åœ°èµ„äº§åº“ï¼Œç”¨äº SEO å†…é“¾
    """
    import json
    BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    ASSETS_FILE = os.path.join(BASE_DIR, "published_assets.json")
    
    # æ„é€ æ–°è®°å½•
    new_record = {
        "title": article.get("title"),
        "url": url,
        "keywords": article.get("keywords"),
        "category_id": article.get("category_id"),
        "summary": article.get("summary"),
        "published_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }
    
    try:
        data = []
        if os.path.exists(ASSETS_FILE):
            with open(ASSETS_FILE, 'r', encoding='utf-8') as f:
                try:
                    data = json.load(f)
                except:
                    data = []
        
        # ç®€å•å»é‡ (æŒ‰ URL)
        existing_idx = next((i for i, item in enumerate(data) if item.get("url") == url), -1)
        if existing_idx >= 0:
            data[existing_idx] = new_record
        else:
            data.append(new_record)
            
        with open(ASSETS_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
            
        print(f"   ğŸ“š [SEO] å·²æ”¶å½•è‡³èµ„äº§åº“ ({len(data)} ç¯‡)")
        
    except Exception as e:
        print(f"   âš ï¸ èµ„äº§åº“å†™å…¥å¤±è´¥: {e}")

if __name__ == "__main__":
    run()
