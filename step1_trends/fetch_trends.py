# trends_generator/fetch_trends.py
"""
çƒ­ç‚¹æŠ“å–ä¸ AI åˆ†ææ¨¡å—
"""
import requests
import json
import os
import re
import time
from datetime import datetime
from dotenv import load_dotenv

# åŠ è½½ .env ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½® DeepSeek API
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY", "sk-your-key-here")
DEEPSEEK_API_URL = "https://api.deepseek.com/v1/chat/completions"

# URLs
BAIDU_HOT_URL = "https://top.baidu.com/board?tab=realtime"
WEIBO_HOT_URL = "https://s.weibo.com/top/summary"
TOUTIAO_HOT_URL = "https://www.toutiao.com/hot-event/hot-board/?origin=toutiao_pc"
BILIBILI_HOT_URL = "https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all"
KR36_HOT_URL = "https://36kr.com/newsflashes"

# æ–‡ä»¶è·¯å¾„ (æŒ‡å‘é¡¹ç›®æ ¹ç›®å½•)
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
TRENDS_FILE = os.path.join(BASE_DIR, "trends_data.json")
CONFIG_FILE = os.path.join(BASE_DIR, "box_artist_config.json")

# é€šç”¨ Header
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Cookie": "SUB=_2AkMSb-1af8NxqwJRmP0SzGvmZY1yyA_EieKkA3HJJRMxHRl-yT9kqmsstRB6POKqfE_JzXqqfE_JzXqqfE_JzXqq; _zap=a1b2c3d4; d_c0=abcd1234;" # ç®€å•çš„ Mock Cookie å¢åŠ æˆåŠŸç‡
}

def fetch_baidu_hot():
    """æŠ“å–ç™¾åº¦çƒ­æœæ¦œ"""
    print("ğŸ“¡ [Baidu] æ­£åœ¨æŠ“å–...")
    try:
        resp = requests.get(BAIDU_HOT_URL, headers=HEADERS, timeout=10)
        resp.encoding = 'utf-8'
        html = resp.text
        titles = re.findall(r'<div class="c-single-text-ellipsis">\s*(.*?)\s*</div>', html)
        clean_titles = [t.strip() for t in titles if t.strip() and "ç½®é¡¶" not in t][:15] # å–å‰15
        print(f"   -> è·å–åˆ° {len(clean_titles)} æ¡")
        return clean_titles
    except Exception as e:
        print(f"   âŒ å¤±è´¥: {e}")
        return []

def fetch_weibo_hot():
    """æŠ“å–å¾®åšçƒ­æœ"""
    print("ğŸ“¡ [Weibo] æ­£åœ¨æŠ“å–...")
    try:
        resp = requests.get(WEIBO_HOT_URL, headers=HEADERS, timeout=10)
        html = resp.text
        # å¾®åšæ ¼å¼: <a href="/weibo?q=xxx" target="_blank">xxx</a>
        # æ’é™¤ "javascript:void(0)" ç­‰ç½®é¡¶å¹¿å‘Š
        titles = re.findall(r'<a href="/weibo\?q=[^"]+" target="_blank">([^<]+)</a>', html)
        clean_titles = [t.strip() for t in titles if t.strip()][:15]
        print(f"   -> è·å–åˆ° {len(clean_titles)} æ¡")
        return clean_titles
    except Exception as e:
        print(f"   âŒ å¤±è´¥: {e}")
        return []

def fetch_toutiao_hot():
    """æŠ“å–å¤´æ¡çƒ­æ¦œ (æŠ–éŸ³/å­—èŠ‚ç³»æ•°æ®)"""
    print("ğŸ“¡ [Toutiao] æ­£åœ¨æŠ“å–...")
    try:
        resp = requests.get(TOUTIAO_HOT_URL, headers=HEADERS, timeout=10)
        data = resp.json()
        
        # è§£æå¤´æ¡ JSON ç»“æ„
        clean_titles = []
        if "fixed_top_data" in data:
            for item in data["fixed_top_data"]:
                clean_titles.append(item.get("Title"))
                
        if "data" in data:
            for item in data["data"]:
                clean_titles.append(item.get("Title"))
                
        # å–å‰15
        clean_titles = clean_titles[:15]
        print(f"   -> è·å–åˆ° {len(clean_titles)} æ¡")
        return clean_titles
    except Exception as e:
        print(f"   âŒ å¤±è´¥: {e}")
        return []

def fetch_bilibili_hot():
    """æŠ“å–Bç«™çƒ­é—¨è§†é¢‘ (å¹´è½»äººè¶‹åŠ¿)"""
    print("ğŸ“¡ [Bilibili] æ­£åœ¨æŠ“å–...")
    try:
        # Bç«™ API å¯¹ Cookie å¾ˆæ•æ„Ÿï¼Œæœ‰æ—¶ç”šè‡³ä¸éœ€è¦ Cookie åªè¦ UA
        # è¿™é‡Œå•ç‹¬å®šä¹‰ Headerï¼Œä¸å¸¦ Cookie
        headers = {
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        }
        resp = requests.get(BILIBILI_HOT_URL, headers=headers, timeout=10)
        data = resp.json()
        
        clean_titles = []
        if data.get("code") == 0 and "data" in data and "list" in data["data"]:
            for item in data["data"]["list"]:
                clean_titles.append(item.get("title"))
                
        clean_titles = clean_titles[:15]
        print(f"   -> è·å–åˆ° {len(clean_titles)} æ¡")
        return clean_titles
    except Exception as e:
        print(f"   âŒ å¤±è´¥: {e}")
        return []

def fetch_36kr_hot():
    """æŠ“å–36æ°ªå¿«è®¯ (è¡Œä¸š/å•†ä¸š)"""
    print("ğŸ“¡ [36Kr] æ­£åœ¨æŠ“å–...")
    try:
        resp = requests.get(KR36_HOT_URL, headers=HEADERS, timeout=10)
        html = resp.text
        
        # ä¼˜åŒ–æå–é€»è¾‘ï¼Œä¸ç”¨ç®€å•çš„æ­£åˆ™é˜²æ­¢æå‰æˆªæ–­
        start_marker = "window.initialState="
        if start_marker in html:
            start_idx = html.find(start_marker) + len(start_marker)
            # æ‰¾åˆ°éšåçš„è„šæœ¬ç»“æŸæ ‡ç­¾æˆ–è€…åˆ†å·
            # ä½† JSON å¯èƒ½åŒ…å«åˆ†å·ï¼Œæœ€ç¨³çš„æ˜¯æ‰¾ </script>
            end_idx = html.find("</script>", start_idx)
            
            json_str = html[start_idx:end_idx].strip()
            # å»æ‰æœ«å°¾å¯èƒ½çš„åˆ†å·
            if json_str.endswith(";"):
                json_str = json_str[:-1]
                
            try:
                data = json.loads(json_str)
                clean_titles = []
                # è·¯å¾„: newsflashCatalogData -> data -> newsflashList -> data -> itemList
                items = data.get("newsflashCatalogData", {}).get("data", {}).get("newsflashList", {}).get("data", {}).get("itemList", [])
                for item in items:
                    title = item.get("templateMaterial", {}).get("widgetTitle")
                    if title:
                        clean_titles.append(title)
                
                clean_titles = clean_titles[:15]
                print(f"   -> è·å–åˆ° {len(clean_titles)} æ¡")
                return clean_titles
                
            except json.JSONDecodeError:
                print("   âš ï¸ 36Kr: JSON è§£æå¤±è´¥")
                return []
        else:
            print("   âš ï¸ 36Kr: æœªæ‰¾åˆ°æ•°æ®æºæ ‡è®°")
            return []
            
    except Exception as e:
        print(f"   âŒ å¤±è´¥: {e}")
        return []

def fetch_baidu_suggestions(seed_words):
    """æŒ–æ˜ç™¾åº¦ä¸‹æ‹‰æ¨èè¯ (ç²¾å‡†æœç´¢éœ€æ±‚)"""
    if not seed_words:
        return []
        
    print(f"â›ï¸  å¼€å§‹æŒ–æ˜ {len(seed_words)} ä¸ªç§å­è¯çš„é•¿å°¾éœ€æ±‚...")
    suggestions = []
    
    for seed in seed_words:
        try:
            # Baidu Suggest API: window.bdsug.sug({q:"...",s:["..."]})
            url = f"http://suggestion.baidu.com/su?wd={seed}&p=3&cb=window.bdsug.sug"
            resp = requests.get(url, headers=HEADERS, timeout=5)
            # ç®€å•çš„æ­£åˆ™æå– s:[...] å†…å®¹
            match = re.search(r's:(\[.*?\])', resp.text)
            if match:
                # è½¬æ¢ç±»ä¼¼ JSON çš„æ•°ç»„å­—ç¬¦ä¸² (è™½ç„¶å®ƒæ˜¯ JS æ•°ç»„ï¼Œä½† python json ä¹Ÿèƒ½è§£å¤§éƒ¨åˆ†)
                # æ³¨æ„ï¼šBaidu æœ‰æ—¶è¿”å›å•å¼•å·ï¼Œpy json éœ€è¦åŒå¼•å·
                raw_list = match.group(1).replace("'", '"')
                try:
                    words = json.loads(raw_list)
                    # é€‰å–å‰ 5 ä¸ªæœ€ç›¸å…³çš„
                    top_words = words[:5]
                    for w in top_words:
                        suggestions.append(f"[æœç´¢éœ€æ±‚] {w}")
                    print(f"   -> '{seed}' æŒ–åˆ°: {len(top_words)} ä¸ª")
                except:
                    pass
            time.sleep(0.5) 
        except Exception as e:
            print(f"   âŒ æŒ–æ˜ '{seed}' å¤±è´¥: {e}")
            
    print(f"   -> æ€»è®¡è·å– {len(suggestions)} ä¸ªç™¾åº¦é•¿å°¾éœ€æ±‚")
    return suggestions

def fetch_1688_suggestions(seed_words):
    """æŒ–æ˜1688ä¸‹æ‹‰æ¨èè¯ (B2Bæºå¤´é‡‡è´­éœ€æ±‚)"""
    if not seed_words:
        return []
        
    print(f"ğŸ­ å¼€å§‹æŒ–æ˜ 1688 (B2B) é•¿å°¾éœ€æ±‚...")
    suggestions = []
    import random
    # éšæœºé€‰å– 10 ä¸ªè¯è¿›è¡ŒæŒ–æ˜ï¼Œé˜²æ­¢è¯·æ±‚è¿‡å¤š
    target_seeds = random.sample(seed_words, min(10, len(seed_words)))
    
    for seed in target_seeds:
        try:
            # 1688 Suggest API
            url = f"https://suggest.1688.com/bin/suggest?code=utf-8&q={seed}"
            resp = requests.get(url, headers=HEADERS, timeout=5)
            data = resp.json()
            if "result" in data:
                top_words = [item['q'] for item in data['result'][:5]]
                for w in top_words:
                    suggestions.append(f"[1688é‡‡è´­] {w}")
                print(f"   -> '{seed}' æŒ–åˆ°: {len(top_words)} ä¸ª")
            time.sleep(0.5)
        except Exception as e:
            print(f"   âŒ 1688æŒ–æ˜ '{seed}' å¤±è´¥: {e}")
            
    print(f"   -> æ€»è®¡è·å– {len(suggestions)} ä¸ª1688é•¿å°¾éœ€æ±‚")
    return suggestions

def fetch_taobao_suggestions(seed_words):
    """æŒ–æ˜æ·˜å®ä¸‹æ‹‰æ¨èè¯ (Cç«¯æ¶ˆè´¹è¶‹åŠ¿)"""
    if not seed_words:
        return []

    print(f"ğŸ›ï¸  å¼€å§‹æŒ–æ˜æ·˜å® (Cç«¯) æ¶ˆè´¹è¶‹åŠ¿...")
    suggestions = []
    import random
    target_seeds = random.sample(seed_words, min(10, len(seed_words)))

    for seed in target_seeds:
        try:
            # Taobao Suggest API
            url = f"https://suggest.taobao.com/sug?code=utf-8&q={seed}&k=1&area=c2c"
            resp = requests.get(url, headers=HEADERS, timeout=5)
            data = resp.json()
            if "result" in data:
                top_words = [item[0] for item in data['result'][:5]]
                for w in top_words:
                    suggestions.append(f"[æ·˜å®çƒ­æœ] {w}")
                print(f"   -> '{seed}' æŒ–åˆ°: {len(top_words)} ä¸ª")
            time.sleep(0.5)
        except Exception as e:
            print(f"   âŒ æ·˜å®æŒ–æ˜ '{seed}' å¤±è´¥: {e}")

    print(f"   -> æ€»è®¡è·å– {len(suggestions)} ä¸ªæ·˜å®é•¿å°¾éœ€æ±‚")
    return suggestions

def analyze_trends_with_ai(trends):
    """ä½¿ç”¨ DeepSeek åˆ†æçƒ­æœä¸åŒ…è£…è¡Œä¸šçš„å…³è”"""
    if not trends:
        return []
        
    print(f"ğŸ§  æ­£åœ¨è¯·æ±‚ DeepSeek åˆ†æ {len(trends)} ä¸ªè¯é¢˜...")
    
    # æ„é€  Prompt
    trends_str = "\n".join([f"- {t}" for t in trends])
    prompt = f"""
    æˆ‘æ˜¯ä¸€ä¸ªåšã€åŒ…è£…å°åˆ·ã€ç¤¼ç›’å®šåˆ¶ã€å“ç‰Œè®¾è®¡ã€‘çš„å·¥å‚ã€‚
    è¯·åˆ†æä»¥ä¸‹å…¨ç½‘çƒ­ç‚¹ï¼Œ**åŠ¡å¿…æŒ‘é€‰å‡º 33 ä¸ª** æœ€é€‚åˆå†™æ–‡ç« çš„è¯é¢˜ï¼ˆæ•°é‡ä¸è¶³æ‰£åˆ†ï¼‰ã€‚
    
    **ç­›é€‰ä¼˜å…ˆçº§ï¼ˆç²¾å‡†è¥é”€ç‰ˆï¼‰ï¼š**
    1. **Sçº§ï¼ˆå¿…é€‰ï¼‰**ï¼šå¸¦æœ‰ `[æœç´¢éœ€æ±‚]` æ ‡è®°çš„å†…å®¹ã€‚ä»¥åŠ**æŠ€æœ¯ç±»é•¿å°¾éœ€æ±‚**ï¼ˆå¦‚ï¼š**å°åˆ·è®¾å¤‡ä»‹ç»/ç»´ä¿®ã€è¡Œä¸šæ ‡å‡†è§£è¯»ã€åŒ…è£…è®¡ç®—å…¬å¼**ï¼‰ã€**è¡Œä¸šå‰æ²¿è¶‹åŠ¿**ï¼ˆæ•°å­—åŒ–ã€AIã€å‡ºæµ·ï¼‰åŠ**è®¾è®¡è¥é”€çƒ­ç‚¹**ï¼ˆå¦‚ï¼š**å›½æ½®è®¾è®¡ã€å“ç‰Œè§†è§‰å‡çº§ã€çƒ­é—¨å¹¿å‘Šåˆ›æ„**ï¼‰ã€‚
    2. **Açº§ï¼ˆé‡ç‚¹ï¼‰**ï¼šèƒ½å…³è”åˆ°â€œå®ä½“äº§å“ã€ç¤¼å“ç»æµã€æ¶ˆè´¹è¡Œä¸šï¼ˆç¾å¦†/é£Ÿå“/ç”µå­ï¼‰â€çš„å•†ä¸šçƒ­ç‚¹ã€‚ä¾‹å¦‚ï¼šâ€œæŸå“ç‰Œè”åç¤¼ç›’â€ã€â€œæ˜¥èŠ‚å¹´è´§æ¶ˆè´¹è¶‹åŠ¿â€ã€‚
    3. **Bçº§ï¼ˆç‰¹å®šå…³è”ï¼‰**ï¼šèƒ½å¼ºè¡Œå…³è”æ­¤è¡Œä¸šæ ‡å‡†çš„ç¤¾ä¼šçƒ­ç‚¹ã€‚ä¾‹å¦‚ï¼šâ€œç¯ä¿æ”¿ç­–ï¼ˆå…³è”ç»¿è‰²åŒ…è£…ï¼‰â€ã€â€œå¿«é€’æ–°è§„ï¼ˆå…³è”æŠ—å‹çº¸ç®±ï¼‰â€ã€‚
    4. **Dçº§ï¼ˆåšå†³å‰”é™¤ï¼‰**ï¼šä»»ä½•æ— æ³•è½¬åŒ–ä¸ºâ€œå–åŒ…è£…ç›’â€çš„çº¯å¨±ä¹å…«å¦ã€æ”¿æ²»æ•æ„Ÿã€è´Ÿé¢ç¤¾ä¼šæ–°é—»ã€‚**å®ç¼ºæ¯‹æ»¥ï¼Œä¸è¦å‡‘æ•°ã€‚**
    
    **è¥é”€æ€è€ƒé€»è¾‘ï¼š**
    - çœ‹åˆ°â€œæ˜æ˜Ÿä»£è¨€â€ï¼Œæ€è€ƒï¼šä»–çš„ç²‰ä¸ä¼šä¹°åŒæ¬¾åº”æ´ç¤¼ç›’å—ï¼Ÿï¼ˆæ˜¯->é€‰ï¼Œå¦->å¼ƒï¼‰
    - çœ‹åˆ°â€œèŠ‚æ—¥â€ï¼Œæ€è€ƒï¼šå•†å®¶éœ€è¦æå‰å¤‡è´§ç¤¼ç›’åŒ…è£…å—ï¼Ÿï¼ˆæ˜¯->é€‰ï¼‰

    çƒ­æœåˆ—è¡¨ï¼ˆå·²æ ‡è®°æ¥æºï¼‰ï¼š
    {trends_str}
    
    å¯¹äºæ¯ä¸ªæŒ‘é€‰å‡ºçš„ç›¸å…³è¯é¢˜ï¼Œè¯·ç»™å‡ºï¼ˆè¯·ä¿ç•™åŸå§‹è¯é¢˜ä¸­çš„[æ¥æº]æ ‡è®°ï¼‰ï¼š
    1. topic: è¯é¢˜åç§° (e.g. "[æœç´¢éœ€æ±‚] åŒ…è£…å®šåˆ¶å“ªå®¶å¥½")
    2. angle: ç»“åˆè§’åº¦ (ä¾‹å¦‚ï¼šåˆ†æäº‹ä»¶ä¸­çš„ç¤¼å“åŒ…è£…å·®å¼‚ã€çƒ­ç‚¹äººç‰©å¸¦ç«çš„åŒæ¬¾è‰²ç³»ç­‰)
    
    è¯·ä¸¥æ ¼è¿”å› JSON æ ¼å¼åˆ—è¡¨ï¼š
    [
        {{"topic": "è¯é¢˜å", "angle": "ç»“åˆè§’åº¦"}}
    ]
    ä¸è¦è¿”å› Markdownã€‚
    """
    
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {DEEPSEEK_API_KEY}"
    }
    
    payload = {
        "model": "deepseek-chat",
        "messages": [
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.7
    }
    
    try:
        if "sk-your-key-here" in DEEPSEEK_API_KEY:
            print("âš ï¸ æœªé…ç½® DeepSeek Keyï¼Œè·³è¿‡ AI åˆ†æã€‚")
            return []

        # æ•°æ®é‡å¤§æ—¶ï¼ŒAPI å“åº”è¾ƒæ…¢ï¼Œå¢åŠ è¶…æ—¶æ—¶é—´åˆ° 120ç§’
        resp = requests.post(DEEPSEEK_API_URL, headers=headers, json=payload, timeout=120)
        result = resp.json()
        
        if "choices" in result:
            content = result["choices"][0]["message"]["content"]
            content = content.replace("```json", "").replace("```", "").strip()
            return json.loads(content)
        else:
            print(f"âŒ API è°ƒç”¨é”™è¯¯: {result}")
            return []
            
    except Exception as e:
        print(f"âŒ AI åˆ†æå¤±è´¥: {e}")
        return []

def main():
    # 0. è¯»å–é…ç½®è·å–ç§å­è¯
    mining_seeds = []
    if os.path.exists(CONFIG_FILE):
        with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
            cfg = json.load(f)
            mining_seeds = cfg.get("mining_seeds", [])

    # 1. å¤šæºæŠ“å–
    all_trends = []
    
    # æŒ–æ˜é•¿å°¾éœ€æ±‚ (ä¼˜å…ˆ)
    all_trends.extend(fetch_baidu_suggestions(mining_seeds))
    all_trends.extend(fetch_1688_suggestions(mining_seeds))
    all_trends.extend(fetch_taobao_suggestions(mining_seeds))
    
    # æ‰‹åŠ¨æ ‡è®°æ¥æº
    for t in fetch_baidu_hot():
        all_trends.append(f"[ç™¾åº¦] {t}")
        
    for t in fetch_weibo_hot():
        all_trends.append(f"[å¾®åš] {t}")
        
    for t in fetch_toutiao_hot():
        all_trends.append(f"[å¤´æ¡] {t}")
        
    # Bç«™åçˆ¬ä¸¥é‡æš‚è·³è¿‡
    # for t in fetch_bilibili_hot():
    #     all_trends.append(f"[Bç«™] {t}")
        
    for t in fetch_36kr_hot():
        all_trends.append(f"[36æ°ª] {t}")
    
    # å»é‡
    unique_trends = list(set(all_trends))
    print(f"ğŸ“Š å…±æ”¶é›†åˆ° {len(unique_trends)} ä¸ªå”¯ä¸€çƒ­ç‚¹è¯é¢˜")

    # 2. åˆ†æ
    analyzed_data = analyze_trends_with_ai(unique_trends)
    
    # 3. å­˜å‚¨
    output = {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "raw_trends_count": len(unique_trends),
        "all_trends_list": unique_trends,  # ä¿å­˜æ‰€æœ‰åŸå§‹çƒ­ç‚¹
        "analyzed_trends": analyzed_data
    }
    
    with open(TRENDS_FILE, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)
        
    print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜è‡³ {TRENDS_FILE}")

if __name__ == "__main__":
    main()