import sys
import os
import requests
import re
import json
import time
import logging
from datetime import datetime
from dotenv import load_dotenv

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from core.skill import BaseSkill
from shared import config

# åŠ è½½ .env ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½® logger
logger = logging.getLogger(__name__)

class TrendSearchSkill(BaseSkill):
    """
    æŠ€èƒ½: å…¨ç½‘çƒ­ç‚¹æŒ–æ˜ (Baidu, Weibo, Toutiao, etc.)
    """
    def __init__(self):
        super().__init__(
            name="trend_search",
            description="ä»ç™¾åº¦ã€å¾®åšã€å¤´æ¡ã€çŸ¥ä¹ã€å°çº¢ä¹¦ç­‰å¹³å°æŠ“å–çƒ­é—¨è¯é¢˜"
        )
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Cookie": "SUB=_2AkMSb-1af8NxqwJRmP0SzGvmZY1yyA_EieKkA3HJJRMxHRl-yT9kqmsstRB6POKqfE_JzXqqfE_JzXqqfE_JzXqq;" 
        }

    def execute(self, input_data: dict) -> list:
        """
        Input: {"mining_seeds": ["seed1", ...]}
        Output: ["raw_trend_1", "raw_trend_2", ...]
        """
        mining_seeds = input_data.get("mining_seeds", [])
        all_trends = []

        print("ğŸ“¡ [TrendSearch] å¼€å§‹å¤šæºæ•°æ®æŠ“å–...")
        
        # ===== ç§å­è¯è½®æ¢ç­–ç•¥ (ä¿æŒè¯é¢˜å¤šæ ·æ€§) =====
        if mining_seeds:
            mining_seeds = self._rotate_seeds(mining_seeds)
        
        # 1. æŒ–æ˜é•¿å°¾éœ€æ±‚
        if mining_seeds:
            all_trends.extend(self._fetch_baidu_suggestions(mining_seeds))
            all_trends.extend(self._fetch_1688_suggestions(mining_seeds))
            all_trends.extend(self._fetch_taobao_suggestions(mining_seeds))
            all_trends.extend(self._fetch_zhihu_hot_questions(mining_seeds))
            all_trends.extend(self._fetch_xiaohongshu_trends(mining_seeds))
            all_trends.extend(self._fetch_google_trends(mining_seeds))

        # 2. æŠ“å–å¹³å°çƒ­æ¦œ
        for t in self._fetch_baidu_hot():
            all_trends.append(f"[ç™¾åº¦] {t}")
        for t in self._fetch_weibo_hot():
            all_trends.append(f"[å¾®åš] {t}")
        for t in self._fetch_toutiao_hot():
            all_trends.append(f"[å¤´æ¡] {t}")
        for t in self._fetch_36kr_hot():
            all_trends.append(f"[36æ°ª] {t}")

        # å»é‡
        unique_trends = list(set(all_trends))
        print(f"ğŸ“Š [TrendSearch] å…±æ”¶é›†åˆ° {len(unique_trends)} ä¸ªå”¯ä¸€çƒ­ç‚¹è¯é¢˜")
        return unique_trends

    # --- Internal Fetch Methods (Moved from fetch_trends.py) ---

    def _rotate_seeds(self, seeds: list) -> list:
        """
        åŸºäºæ—¥æœŸçš„ç§å­è¯è½®æ¢ï¼Œä¿æŒè¯é¢˜å¤šæ ·æ€§
        æ¯å¤©ä½¿ç”¨ä¸åŒçš„ç§å­è¯ç»„åˆï¼Œé¿å…å†…å®¹åŒè´¨åŒ–
        """
        import random
        from datetime import datetime
        
        # å®šä¹‰ç§å­è¯åˆ†ç±» (åŸºäºå…³é”®è¯åŒ¹é…)
        SEED_GROUPS = {
            "äº§å“ç±»": ["ç¤¼ç›’", "çº¸ç®±", "é£æœºç›’", "æ‰‹æè¢‹", "åŒ…è£…ç›’", "çº¸ç›’", "å½©ç›’", "å†…æ‰˜", "å†…è¡¬"],
            "å·¥è‰ºç±»": ["çƒ«é‡‘", "UV", "è¦†è†œ", "å‡»å‡¸", "å°åˆ·", "æ¨¡åˆ‡", "åˆ¶ç‰ˆ"],
            "è¡Œä¸šè¶‹åŠ¿": ["å›½æ½®", "æç®€", "æ™ºèƒ½", "å¯é™è§£", "ç¢³ä¸­å’Œ", "æ•°å­—åŒ–", "AI", "è¶‹åŠ¿"],
            "å±•ä¼šæ´»åŠ¨": ["å±•", "ä¼š", "å³°ä¼š", "è®ºå›", "å¤§èµ›"],
            "é€šç”¨è½¬åŒ–": ["å®šåˆ¶", "å‚å®¶", "æ‰¹å‘", "æºå¤´", "ç›´é”€", "å…è´¹", "æŠ¥ä»·"]
        }
        
        # æŒ‰æ—¥æœŸé€‰æ‹©ä¸»åŠ›åˆ†ç»„ (0=å‘¨ä¸€, 6=å‘¨æ—¥)
        weekday = datetime.now().weekday()
        group_schedule = ["äº§å“ç±»", "å·¥è‰ºç±»", "è¡Œä¸šè¶‹åŠ¿", "å±•ä¼šæ´»åŠ¨", "é€šç”¨è½¬åŒ–", "äº§å“ç±»", "è¡Œä¸šè¶‹åŠ¿"]
        primary_group = group_schedule[weekday]
        
        # åˆ†ç±»ç§å­è¯
        categorized = {k: [] for k in SEED_GROUPS}
        uncategorized = []
        
        for seed in seeds:
            matched = False
            for group, keywords in SEED_GROUPS.items():
                if any(kw in seed for kw in keywords):
                    categorized[group].append(seed)
                    matched = True
                    break
            if not matched:
                uncategorized.append(seed)
        
        # æ„å»ºä»Šæ—¥ç§å­ç»„åˆ: ä¸»åŠ›ç»„50% + å…¶ä»–ç»„å„10% + æœªåˆ†ç±»20%
        result = []
        
        # ä¸»åŠ›ç»„ (æœ€å¤š30ä¸ª)
        primary_seeds = categorized.get(primary_group, [])
        result.extend(random.sample(primary_seeds, min(30, len(primary_seeds))))
        
        # å…¶ä»–ç»„å„å–5ä¸ª
        for group, group_seeds in categorized.items():
            if group != primary_group and group_seeds:
                result.extend(random.sample(group_seeds, min(5, len(group_seeds))))
        
        # æœªåˆ†ç±»å–10ä¸ª
        if uncategorized:
            result.extend(random.sample(uncategorized, min(10, len(uncategorized))))
        
        # æ‰“ä¹±é¡ºåº
        random.shuffle(result)
        
        print(f"ğŸ”„ [SeedRotation] ä»Šæ—¥ä¸»åŠ›: {primary_group} | ç§å­æ•°: {len(result)} (åŸ{len(seeds)})")
        return result

    def _fetch_baidu_hot(self):
        try:
            resp = requests.get("https://top.baidu.com/board?tab=realtime", headers=self.headers, timeout=10)
            resp.encoding = 'utf-8'
            titles = re.findall(r'<div class="c-single-text-ellipsis">\s*(.*?)\s*</div>', resp.text)
            return [t.strip() for t in titles if t.strip() and "ç½®é¡¶" not in t][:15]
        except Exception as e:
            print(f"   âŒ [Baidu] å¤±è´¥: {e}")
            return []

    def _fetch_weibo_hot(self):
        try:
            resp = requests.get("https://s.weibo.com/top/summary", headers=self.headers, timeout=10)
            titles = re.findall(r'<a href="/weibo\?q=[^"]+" target="_blank">([^<]+)</a>', resp.text)
            return [t.strip() for t in titles if t.strip()][:15]
        except Exception as e:
            print(f"   âŒ [Weibo] å¤±è´¥: {e}")
            return []

    def _fetch_toutiao_hot(self):
        try:
            resp = requests.get("https://www.toutiao.com/hot-event/hot-board/?origin=toutiao_pc", headers=self.headers, timeout=10)
            data = resp.json()
            titles = []
            if "fixed_top_data" in data:
                titles.extend([i.get("Title") for i in data["fixed_top_data"]])
            if "data" in data:
                titles.extend([i.get("Title") for i in data["data"]])
            return titles[:15]
        except Exception as e:
            print(f"   âŒ [Toutiao] å¤±è´¥: {e}")
            return []

    def _fetch_36kr_hot(self):
        try:
            resp = requests.get("https://36kr.com/newsflashes", headers=self.headers, timeout=10)
            html = resp.text
            start_marker = "window.initialState="
            if start_marker in html:
                start_idx = html.find(start_marker) + len(start_marker)
                end_idx = html.find("</script>", start_idx)
                json_str = html[start_idx:end_idx].strip().rstrip(";")
                data = json.loads(json_str)
                items = data.get("newsflashCatalogData", {}).get("data", {}).get("newsflashList", {}).get("data", {}).get("itemList", [])
                titles = []
                for item in items:
                    t = item.get("templateMaterial", {}).get("widgetTitle")
                    if t: titles.append(t)
                return titles[:15]
            return []
        except Exception as e:
            print(f"   âŒ [36Kr] å¤±è´¥: {e}")
            return []

    def _fetch_baidu_suggestions(self, seeds):
        suggestions = []
        for seed in seeds:
            try:
                url = f"http://suggestion.baidu.com/su?wd={seed}&p=3&cb=window.bdsug.sug"
                resp = requests.get(url, headers=self.headers, timeout=5)
                match = re.search(r's:(\[.*?\])', resp.text)
                if match:
                    words = json.loads(match.group(1).replace("'", '"'))[:5]
                    suggestions.extend([f"[æœç´¢éœ€æ±‚] {w}" for w in words])
            except Exception as e:
                logger.debug(f"[ç™¾åº¦å»ºè®®] {seed} æŠ“å–å¤±è´¥: {e}")
        return suggestions

    def _fetch_1688_suggestions(self, seeds):
        suggestions = []
        import random
        for seed in random.sample(seeds, min(10, len(seeds))):
             try:
                url = f"https://suggest.1688.com/bin/suggest?code=utf-8&q={seed}"
                resp = requests.get(url, headers=self.headers, timeout=5)
                data = resp.json()
                if "result" in data:
                    suggestions.extend([f"[1688é‡‡è´­] {i['q']}" for i in data['result'][:5]])
             except Exception as e:
                logger.debug(f"[1688å»ºè®®] {seed} æŠ“å–å¤±è´¥: {e}")
        return suggestions

    def _fetch_taobao_suggestions(self, seeds):
        suggestions = []
        import random
        for seed in random.sample(seeds, min(10, len(seeds))):
            try:
                url = f"https://suggest.taobao.com/sug?code=utf-8&q={seed}&k=1&area=c2c"
                resp = requests.get(url, headers=self.headers, timeout=5)
                data = resp.json()
                if "result" in data:
                    suggestions.extend([f"[æ·˜å®çƒ­æœ] {i[0]}" for i in data['result'][:5]])
            except Exception as e:
                logger.debug(f"[æ·˜å®å»ºè®®] {seed} æŠ“å–å¤±è´¥: {e}")
        return suggestions
    
    def _fetch_zhihu_hot_questions(self, seeds):
        questions = []
        import random
        for seed in random.sample(seeds, min(8, len(seeds))):
            try:
                url = f"https://www.zhihu.com/api/v4/search_v3?t=general&q={seed}&offset=0&limit=5"
                headers = {**self.headers, "Referer": "https://www.zhihu.com/search"}
                resp = requests.get(url, headers=headers, timeout=8)
                if resp.status_code == 200:
                    data = resp.json()
                    for item in data.get("data", [])[:3]:
                        if item.get("type") == "search_result":
                            obj = item.get("object", {})
                            title = obj.get("title", "") or obj.get("question", {}).get("title", "")
                            if title:
                                clean = re.sub(r'<[^>]+>', '', title)
                                questions.append(f"[çŸ¥ä¹é—®ç­”] {clean}")
            except Exception as e:
                logger.debug(f"[çŸ¥ä¹é—®ç­”] {seed} æŠ“å–å¤±è´¥: {e}")
        return list(set(questions))

    def _fetch_xiaohongshu_trends(self, seeds):
        trends = []
        import random
        for seed in random.sample(seeds, min(6, len(seeds))):
            try:
                url = f"https://edith.xiaohongshu.com/api/sns/web/v1/search/hot_list"
                headers = {**self.headers, "Referer": "https://www.xiaohongshu.com/"}
                resp = requests.get(url, headers=headers, timeout=8)
                if resp.status_code == 200:
                    data = resp.json()
                    if data.get("success"):
                        for item in data["data"].get("list", [])[:10]:
                            if any(k in item.get("title", "") for k in ["åŒ…è£…","ç¤¼ç›’","é€ç¤¼"]):
                                trends.append(f"[å°çº¢ä¹¦] {item['title']}")
                        break
            except Exception as e:
                logger.debug(f"[å°çº¢ä¹¦] {seed} æŠ“å–å¤±è´¥: {e}")
        
        scenes = ["å¼€ç®±ä½“éªŒ","é€ç¤¼æ¨è","é«˜çº§æ„ŸåŒ…è£…"]
        for seed in random.sample(seeds, min(3, len(seeds))):
            for s in random.sample(scenes, 2):
                trends.append(f"[å°çº¢ä¹¦] {seed}{s}")
        return list(set(trends))

    def _fetch_google_trends(self, seeds):
        trends = []
        keywords = ["custom packaging", "gift box wholesale", "mailer box"]
        for kw in keywords:
            try:
                url = f"https://trends.google.com/trends/api/autocomplete/{kw.replace(' ', '%20')}?hl=en-US"
                resp = requests.get(url, headers={"User-Agent": self.headers["User-Agent"]}, timeout=8)
                text = resp.text[5:] if resp.text.startswith(")]}'") else resp.text
                data = json.loads(text)
                for t in data.get("default", {}).get("topics", [])[:3]:
                    trends.append(f"[è°·æ­Œè¶‹åŠ¿] {t['title']}")
            except Exception as e:
                logger.debug(f"[è°·æ­Œè¶‹åŠ¿] {kw} æŠ“å–å¤±è´¥: {e}")
        return list(set(trends))
