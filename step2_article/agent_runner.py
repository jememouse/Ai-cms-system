import sys
import os
import json
import time

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from agents.chief_editor import ChiefEditorAgent
from shared.feishu_client import FeishuClient
from shared import config

def run():
    print("\n" + "=" * 50)
    print("ğŸ¤– å¯åŠ¨ Agentic Workflow (Step 2: Article Gen)")
    print("=" * 50 + "\n")
    
    # Init
    editor = ChiefEditorAgent()
    client = FeishuClient()
    
    # Load Topics (From Feishu for Persistence)
    print("â˜ï¸ æ­£åœ¨ä»é£ä¹¦æ‹‰å– Ready çŠ¶æ€çš„é€‰é¢˜...")
    
    # Fetch Ready topics from Feishu
    # Use pagination loop if needed, but for now we fetch up to MAX_GENERATE_PER_CATEGORY * 3 to be safe
    # We fetch by status 'Ready'
    
    pending_topics = client.fetch_records_by_status(config.STATUS_READY, limit=100)
    
    if not pending_topics:
        print("âŒ é£ä¹¦ä¸­æ²¡æœ‰æ‰¾åˆ° Ready çŠ¶æ€çš„é€‰é¢˜ï¼Œè¯·å…ˆè¿è¡Œ Step 1")
        return

    print(f"ğŸ“‹ ä»é£ä¹¦è·å–åˆ° {len(pending_topics)} ä¸ª Ready é€‰é¢˜")
    
    # Load Config Limit
    max_limit = config.MAX_GENERATE_PER_CATEGORY
    print(f"âš™ï¸  æ¯åˆ†ç±»å¤„ç†ä¸Šé™: {max_limit}")

    # 3. åˆ†ç»„ä¸ Round-Robin æ’åº
    # Group by Category
    from collections import defaultdict
    grouped_topics = defaultdict(list)
    for t in pending_topics:
        # Note: fetch_records_by_status returns dict with keys: record_id, topic, category...
        # We need to map them to the format expected below or adjust below code
        # The return dict keys are: record_id, topic, category, title, html_content...
        # We need 'Topic', 'å¤§é¡¹åˆ†ç±»'
        
        # Mapping for compatibility
        t['Topic'] = t['topic']
        t['å¤§é¡¹åˆ†ç±»'] = t['category']
        
        cat = t.get('å¤§é¡¹åˆ†ç±»', 'æœªåˆ†ç±»')
        grouped_topics[cat].append(t)
    
    print("ğŸ“Š å¾…å¤„ç†é€‰é¢˜åˆ†å¸ƒ:")
    for cat, items in grouped_topics.items():
        print(f"   - {cat}: {len(items)} æ¡")
        
    # Round-Robin Merge
    sorted_topics = []
    from itertools import zip_longest
    # å–æ¯ä¸ªåˆ†ç±»çš„å‰ max_limit æ¡
    lists = [items[:max_limit] for items in grouped_topics.values()]
    
    for items in zip_longest(*lists):
        for item in items:
            if item is not None:
                sorted_topics.append(item)
                
    print(f"ğŸ”„ å‡è¡¡æ’åºåå…± {len(sorted_topics)} æ¡ä»»åŠ¡")
    
    import random
    from datetime import datetime
    
    # 4. Execute
    for idx, item in enumerate(sorted_topics):
        print(f"\n--- [{idx + 1}/{len(sorted_topics)}] {item['å¤§é¡¹åˆ†ç±»']} | {item['Topic'][:30]}... ---")
        
        article = editor.write_article(item['Topic'], item['å¤§é¡¹åˆ†ç±»'])
        
        if article:
            # Update Feishu Record (Status: Ready -> Pending)
            current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            # Fields to update
            fields = {
                "Title": article.get('title'),
                "HTML_Content": article.get('html_content'),
                "Status": config.STATUS_PENDING,
                "å…³é”®è¯": article.get('keywords'),
                "æ‘˜è¦": article.get('summary'),
                "æè¿°": article.get('description'),
                "Tags": article.get('tags'),
                "ç”Ÿæˆæ—¶é—´": current_time, 
                # "é€‰é¢˜ç”Ÿæˆæ—¶é—´": item.get('created_at', ''), # é€‰é¢˜æ—¶é—´å·²å­˜åœ¨ï¼Œæ— éœ€æ›´æ–°
                "One_Line_Summary": article.get('one_line_summary', ''),
                "Schema_FAQ": json.dumps(article.get('schema_faq', []), ensure_ascii=False),
                "Key_Points": json.dumps(article.get('key_points', []), ensure_ascii=False)
            }
            
            # Check if we have record_id (From Feishu Fetch)
            record_id = item.get('record_id')
            if record_id:
                success = client.update_record(record_id, fields)
                if success:
                    print(f"   ğŸ’¾ å·²åœ¨é£ä¹¦æ›´æ–°è®°å½• (ID: {record_id}, Status: Pending)")
            else:
                # Fallback: Create new (Should not happen in new flow)
                client.create_record(fields)
                print("   âš ï¸ æœªæ‰¾åˆ° record_idï¼Œåˆ›å»ºäº†æ–°è®°å½•")
        
        # Random Interval
        # Optimization: 5-10s to avoid rate limit
        wait_time = random.uniform(5, 10)
        print(f"   â³ ç­‰å¾… {wait_time:.1f} ç§’...")
        time.sleep(wait_time)
        
    # Update JSON
    with open(INPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(topics, f, ensure_ascii=False, indent=2)

if __name__ == "__main__":
    run()
