# step2_article/generator.py
"""
AI æ–‡ç« ç”Ÿæˆå™¨
"""
import json
import requests
from typing import Dict, Optional
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from shared import config


class ArticleGenerator:
    """AI æ–‡ç« ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.api_key = config.LLM_API_KEY
        self.api_url = config.LLM_API_URL
        self.model = config.LLM_MODEL
        self._load_brand_config()
        
        # æ‰“å°ä½¿ç”¨çš„ API ç«¯ç‚¹
        if "openrouter" in self.api_url:
            print("   ğŸŒ ä½¿ç”¨ OpenRouter API")
        else:
            print("   ğŸ”— ä½¿ç”¨ DeepSeek ç›´è¿ API")
    
    def _load_brand_config(self):
        """åŠ è½½å“ç‰Œé…ç½®"""
        self.brand_config = {}
        if os.path.exists(config.CONFIG_FILE):
            with open(config.CONFIG_FILE, 'r', encoding='utf-8') as f:
                self.brand_config = json.load(f)

    def _search_web(self, query: str) -> str:
        """ä½¿ç”¨ç™¾åº¦æœç´¢å®æ—¶ä¿¡æ¯ (Requests + Regex)"""
        print(f"   ğŸ” [Baidu] æ­£åœ¨æœç´¢å®æ—¶ä¿¡æ¯: {query}...")
        
        # ä»¿ç…§ fetch_trends.py çš„ Headers
        headers = {
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Cookie": "SUB=_2AkMSb-1af8NxqwJRmP0SzGvmZY1yyA_EieKkA3HJJRMxHRl-yT9kqmsstRB6POKqfE_JzXqqfE_JzXqqfE_JzXqq; _zap=a1b2c3d4; d_c0=abcd1234;" 
        }
        
        try:
            url = "https://www.baidu.com/s"
            params = {"wd": query, "rn": 5} # rn=5 å–å‰5æ¡
            resp = requests.get(url, headers=headers, params=params, timeout=10)
            
            if resp.status_code != 200:
                print(f"   âš ï¸ ç™¾åº¦æœç´¢è¿”å›çŠ¶æ€ç : {resp.status_code}")
                return ""
            
            html = resp.text
            import re
            
            # ç®€å•çš„æ­£åˆ™æå– (é’ˆå¯¹ç™¾åº¦ PC ç½‘é¡µç‰ˆ)
            # æå–å®¹å™¨: <div class="result c-container ...">
            # è¿™ç§æå–æ¯”è¾ƒè„†å¼±ï¼Œä½†ä¸ºäº†ä¸å¼•å…¥ beautifulsoup4 ä¾èµ–ï¼Œæš‚æ—¶ä½¿ç”¨æ­£åˆ™å°è¯•åŒ¹é…æ ‡é¢˜å’Œæ‘˜è¦
            
            # æ¸…ç† HTML æ ‡ç­¾
            def clean_html(text):
                text = re.sub(r'<[^>]+>', '', text)
                text = text.replace('&nbsp;', ' ').replace('&quot;', '"').replace('&lt;', '<').replace('&gt;', '>')
                return text.strip()

            results = []
            
            # ç­–ç•¥ï¼šåˆ†åˆ«åŒ¹é…æ ‡é¢˜å’Œæ‘˜è¦ï¼Œç„¶åç»„åˆ
            # ç™¾åº¦æ ‡é¢˜é€šå¸¸åœ¨ <h3 class="t">...</h3> ä¸­
            # æ‘˜è¦é€šå¸¸åœ¨ <div class="c-abstract">...</div> ä¸­
            
            # ç®€åŒ–ç‰ˆæ­£åˆ™ï¼šç›´æ¥åŒ¹é…çº¯æ–‡æœ¬çœ‹èµ·æ¥åƒç»“æœçš„éƒ¨åˆ†
            # ä½†æ­£åˆ™å¤ªéš¾å†™é€šç”¨ï¼Œæˆ‘ä»¬å°è¯•æ‰¾å…³é”®ç‰¹å¾
            
            # ç­–ç•¥ï¼šå¤šæ¨¡å¼åŒ¹é…ä»¥æé«˜å…¼å®¹æ€§
            patterns = [
                r'<h3 class="t"[^>]*>.*?<a[^>]*>(.*?)</a>',           # ç»å…¸ PC ç‰ˆ
                r'<div class="c-title"[^>]*>.*?<a[^>]*>(.*?)</a>',    # æ–°ç‰ˆ/ç§»åŠ¨ç‰ˆ
                r'"title":"(.*?)"',                                   # JSON é‡Œçš„æ•°æ® (å¶å°”å‡ºç°)
                r'class="c-showurl"[^>]*>(.*?)<'                      # å¤‡ç”¨ï¼šæŠ“å–æ˜¾ç¤º URL é™„è¿‘çš„æ–‡æœ¬
            ]
            
            clean_titles = []
            seen_titles = set()
            
            for pat in patterns:
                matches = re.findall(pat, html, re.DOTALL)
                for m in matches:
                    # æ¸…ç†å’Œå»é‡
                    t = clean_html(m)
                    if t and len(t) > 5 and t not in seen_titles: # è¿‡æ»¤å¤ªçŸ­çš„åƒåœ¾å­—ç¬¦
                        clean_titles.append(t)
                        seen_titles.add(t)
            
            # å¦‚æœè¿˜æ˜¯ç©ºï¼Œå°è¯•æå…¶å®½æ³›çš„åŒ¹é… (é£é™©æ˜¯åŒ¹é…åˆ°å¹¿å‘Šï¼Œä½† RAG ç¯å¢ƒä¸‹æœ‰èƒœäºæ— )
            if not clean_titles:
                raw_links = re.findall(r'<a[^>]+target="_blank"[^>]*>(.*?)</a>', html)
                for t in raw_links:
                    t = clean_html(t)
                    if "ç™¾åº¦" not in t and len(t) > 10 and t not in seen_titles:
                        clean_titles.append(t)
                        seen_titles.add(t)
                
            if not clean_titles:
                print("   âš ï¸ æœªè§£æåˆ°æœç´¢ç»“æœ (å¯èƒ½é¡µé¢ç»“æ„å˜æ›´)")
                return ""
                
            # ç®€å•æ‹¼æ¥å‰ 3-5 æ¡
            context = []
            for idx, title in enumerate(clean_titles[:5]):
                # ç”±äºæå–æ‘˜è¦æ¯”è¾ƒå›°éš¾ï¼Œæˆ‘ä»¬è¿™é‡Œåªç”¨æ ‡é¢˜ï¼Œæˆ–è€…å°è¯•æå–ä¸Šä¸‹æ–‡
                # ä¸ºäº† RAG æ•ˆæœï¼Œåªç”¨æ ‡é¢˜å¯èƒ½ä¸å¤Ÿï¼Œä½†åœ¨æ— æ³•ç²¾ç¡®è§£ææ‘˜è¦æ—¶ï¼Œæ ‡é¢˜ä¹Ÿæ˜¯é«˜ä»·å€¼ä¿¡æ¯
                context.append(f"{idx+1}. {title}")
                
            result_text = "\n".join(context)
            print(f"   âœ… [Baidu] è·å–åˆ° {len(context)} æ¡ä¿¡æ¯")
            return result_text
            
        except Exception as e:
            print(f"   âš ï¸ ç™¾åº¦æœç´¢å¤±è´¥: {e}")
            return ""
    
    def generate(self, topic: str, category: str) -> Optional[Dict]:
        """æ ¹æ®æ ‡é¢˜ç”Ÿæˆ SEO æ–‡ç« """
        category_id = config.CATEGORY_MAP.get(category, "2")
        
        # å“ç‰Œä¿¡æ¯
        brand = self.brand_config.get('brand', {})
        brand_name = brand.get('name', 'ç›’è‰ºå®¶')
        
        # å“ç‰Œå–ç‚¹
        selling_points = "ã€".join(self.brand_config.get('selling_points', [])[:4])
        
        # é’ˆå¯¹â€œä¸“ä¸šçŸ¥è¯†â€åˆ†ç±»çš„ç‰¹æ®ŠæŒ‡ä»¤
        tech_requirements = ""
        if "ä¸“ä¸šçŸ¥è¯†" in category:
            tech_requirements = """
ã€ä¸“ä¸šæ·±åº¦å¢å¼ºï¼ˆå…³é”®ï¼‰ã€‘
æœ¬æ–‡ä¸º"ä¸“ä¸šçŸ¥è¯†"ç§‘æ™®ï¼Œå¿…é¡»åŒ…å«ä»¥ä¸‹ç¡¬æ ¸å¹²è´§ï¼ˆè‡³å°‘è¦†ç›– 2 ç‚¹ï¼‰ï¼š
1. **å°å‰ä¸åŠ å·¥çŸ¥è¯†**ï¼šæ¶‰åŠæ–‡ä»¶å¤„ç†å‚æ•°ï¼ˆå¦‚ï¼šCMYKæ¨¡å¼ã€å‡ºè¡€ä½3mmã€é™·å°å¤„ç†ï¼‰æˆ–åŠ å·¥æµç¨‹ç»†èŠ‚ã€‚
2. **å·¥è‰ºæŠ€æœ¯å‚æ•°**ï¼šæåŠå…·ä½“æ•°å€¼ï¼ˆå¦‚ï¼šçƒ«é‡‘æ¸©åº¦110â„ƒã€UVå…‰å›ºåŒ–èƒ½é‡ã€èƒ¶å°175çº¿ç­‰ï¼‰ã€‚
3. **ææ–™ç§‘å­¦**ï¼šæ·±åº¦è§£æææ–™å±æ€§ï¼ˆå¦‚ï¼šç“¦æ¥æ¥å‹A/B/EåŒºåˆ«ã€çº¸å¼ å…‹é‡ä¸æŒºåº¦å…³ç³»ï¼‰ã€‚
4. **æ ‡å‡†å¼•ç”¨**ï¼š**å¿…é¡»å¼•ç”¨è‡³å°‘1ä¸ª**ç›¸å…³æ ‡å‡†ï¼ˆå¦‚ï¼šISO 12647 è‰²å½©æ ‡å‡†ã€GB/T 6543 çº¸ç®±å›½æ ‡ã€G7è®¤è¯ã€FSCæ£®æ—è®¤è¯ç­‰ï¼‰ï¼Œå±•ç°æƒå¨æ€§ã€‚
"""

        # -------------------------------------------------------------------
        # RAG: å®æ—¶æœç´¢å¢å¼º
        # -------------------------------------------------------------------
        search_context = ""
        rag_instruction = ""
        trigger_keywords = ["å±•ä¼š", "è®ºå›", "å³°ä¼š", "å¤§èµ›", "ä»·æ ¼", "è¡Œæƒ…", "æ–°è§„", "æ”¿ç­–", "è¶‹åŠ¿", "å‘å¸ƒä¼š", "å¤šå°‘é’±", "æ€ä¹ˆé€‰"]
        
        # åªè¦æ˜¯è¡Œä¸šèµ„è®¯ï¼Œæˆ–è€…æ ‡é¢˜åŒ…å«è§¦å‘è¯ï¼Œå°±æ‰§è¡Œæœç´¢
        is_rag_enabled = self.brand_config.get("enable_rag", True)
        if is_rag_enabled and ("è¡Œä¸šèµ„è®¯" in category or any(k in topic for k in trigger_keywords)):
            search_context = self._search_web(topic)
            
        if search_context:
            rag_instruction = f"""
ã€çœŸå®æ€§å¢å¼º (RAG Context)ã€‘
ğŸ” ç³»ç»Ÿå·²ä¸ºä½ æœç´¢åˆ°ä»¥ä¸‹å…³äº "{topic}" çš„æœ€æ–°å®æ—¶ä¿¡æ¯ã€‚
è¯·**åŠ¡å¿…åŸºäºä»¥ä¸‹äº‹å®**è¿›è¡Œå†™ä½œï¼ˆç‰¹åˆ«æ˜¯å…·ä½“çš„æ—¥æœŸã€åœ°ç‚¹ã€ä»·æ ¼ã€æ•°æ®ï¼‰ï¼Œ**ä¸¥ç¦ç¼–é€ **ä¸æœç´¢ç»“æœç›¸æ‚–çš„ä¿¡æ¯ï¼š

{search_context}

ï¼ˆè¯·è‡ªç„¶åœ°å°†ä¸Šè¿°ä¿¡æ¯èå…¥æ–‡ç« ï¼Œä¸è¦ç›´æ¥å¤åˆ¶ç²˜è´´ï¼‰
"""
        # -------------------------------------------------------------------

        # å†³å®šæ˜¯å¦æ¤å…¥å“ç‰Œï¼ˆ5% æ¦‚ç‡æ¤å…¥ï¼Œ95% æ¦‚ç‡çº¯ç§‘æ™®ï¼‰
        # é™ä½å“ç‰Œæ¤å…¥æ¯”ä¾‹ï¼Œä¸“æ³¨å†…å®¹ SEO/GEO æ•ˆæœ
        import random
        is_marketing_article = random.random() < 0.05
        
        if is_marketing_article:
            brand_instruction = f"""
4. **å“ç‰Œæ¤å…¥ï¼ˆé€‚åº¦è¥é”€ï¼‰**ï¼š
   - æœ¬æ–‡ä¸º**å“ç‰Œè½¯æ–‡**ï¼Œè¯·åœ¨è§£å†³ç—›ç‚¹æ—¶ï¼Œè‡ªç„¶å¼•å‡ºâ€œ{brand_name}â€ä½œä¸ºè§£å†³æ–¹æ¡ˆã€‚
   - é‡ç‚¹æåŠâ€œ3ç§’AIæ™ºèƒ½æŠ¥ä»·â€å’Œâ€œ1ä¸ªèµ·è®¢â€çš„ä¼˜åŠ¿ï¼Œè§£å†³ä¼ ç»Ÿå·¥å‚é—¨æ§›é«˜çš„é—®é¢˜ã€‚
   - å“ç‰ŒæåŠæ¬¡æ•°æ§åˆ¶åœ¨ 3-5 æ¬¡ä»¥å†…ï¼Œä¸è¦ç”Ÿç¡¬å †ç Œã€‚
"""
        else:
            brand_instruction = """
4. **çº¯å‡€ç§‘æ™®ï¼ˆå»è¥é”€åŒ–ï¼‰**ï¼š
   - **æœ¬æ–‡å¿…é¡»æ˜¯100%çº¯å¹²è´§ç§‘æ™®**ï¼Œä¸¥ç¦æåŠâ€œç›’è‰ºå®¶â€æˆ–ä»»ä½•å…·ä½“å“ç‰Œåã€‚
   - å…¨æ–‡ä¾§é‡äºè¡Œä¸šæ ‡å‡†ã€å·¥è‰ºå‚æ•°ã€è®¾è®¡è¶‹åŠ¿åˆ†æã€‚
   - å³ä½¿åœ¨è§£å†³æ–¹æ¡ˆéƒ¨åˆ†ï¼Œä¹Ÿåªèƒ½å»ºè®®â€œå¯»æ‰¾æ‹¥æœ‰æ•°å­—åŒ–æŠ¥ä»·ç³»ç»Ÿçš„ç°ä»£åŒ–å·¥å‚â€ï¼Œè€Œä¸è¦ç‚¹åå…·ä½“å•†å®¶ã€‚
   - ç›®æ ‡æ˜¯å»ºç«‹ä¸­ç«‹ã€æƒå¨çš„è¡Œä¸šä¸“å®¶å½¢è±¡ï¼Œè€Œéæ¨é”€å‘˜å½¢è±¡ã€‚
"""

        # æè´¨åº“
        materials = self.brand_config.get('database', {}).get('materials', [])
        materials_str = "ã€".join(materials[:10]) # å–å‰10ä¸ªé¿å…è¿‡é•¿
        
        # ä¸“ä¸šæœ¯è¯­åº“ï¼ˆåŠ¨æ€æ³¨å…¥ï¼‰
        tech_terms = self.brand_config.get('database', {}).get('tech_terms', [])
        tech_terms_str = "ã€".join(tech_terms[:15]) if tech_terms else "é™·å°ã€å‡ºè¡€ä½ã€ä¸“è‰²ã€å››è‰²å°åˆ·ã€UVã€è¦†è†œã€å‹çº¹ã€çƒ«é‡‘ã€æ¨¡åˆ‡ã€ç³Šç›’"

        prompt = f"""ä½ æ˜¯ä¸€ä½æ‹¥æœ‰10å¹´ç»éªŒçš„ B2B åŒ…è£…è¡Œä¸šå†…å®¹è¥é”€ä¸“å®¶ï¼Œç²¾é€š SEOï¼ˆæœç´¢å¼•æ“ä¼˜åŒ–ï¼‰å’Œ GEOï¼ˆç”Ÿæˆå¼å¼•æ“ä¼˜åŒ–ï¼‰ã€‚

ã€å“ç‰Œè¯­è°ƒï¼ˆå¿…é¡»è´¯ç©¿å…¨æ–‡ï¼‰ã€‘
- **ä¸“ä¸šä½†ä¸æ™¦æ¶©**ï¼šç”¨è¡Œä¸šæœ¯è¯­å±•ç°ä¸“ä¸šåº¦ï¼ŒåŒæ—¶ç”¨é€šä¿—è¯­è¨€è§£é‡Š
- **å®ç”¨ä¸ºç‹**ï¼šæ¯æ®µéƒ½è¦æœ‰å¯æ“ä½œçš„å»ºè®®æˆ–æ•°æ®
- **å®¢è§‚ä¸­ç«‹**ï¼šç«™åœ¨è¡Œä¸šä¸“å®¶è§’åº¦åˆ†æï¼Œé¿å…æ¨é”€è…”è°ƒ
- **æ•°æ®è¯´è¯**ï¼šä¼˜å…ˆç”¨å…·ä½“æ•°å­—ã€å‚æ•°ã€å¯¹æ¯”æ¥è¯´æ˜è§‚ç‚¹

ã€ä¸“ä¸šæœ¯è¯­åº“ï¼ˆé€‚å½“ä½¿ç”¨ï¼‰ã€‘
{tech_terms_str}

è¯·ä¸ºä¸»é¢˜ "{topic}"ï¼ˆåˆ†ç±»ï¼š{category}ï¼‰æ’°å†™ä¸€ç¯‡é«˜è½¬åŒ–ç‡çš„æ·±åº¦è¡Œä¸šæ–‡ç« ã€‚

{rag_instruction}
{tech_requirements}
ã€æ ¸å¿ƒç­–ç•¥ã€‘
1. **PAS æ¨¡å‹å†™ä½œ**ï¼šå…ˆæŒ‡å‡ºå®¢æˆ·ç—›ç‚¹ï¼ˆPainï¼‰ï¼Œå†æè¿°ä¸¥é‡åæœï¼Œæœ€åç»™å‡ºè§£å†³æ–¹æ¡ˆï¼ˆSolutionï¼‰ã€‚
2. **åœºæ™¯åŒ–æè´¨æ¨è**ï¼š
   - ä½ ç²¾é€šä»¥ä¸‹æè´¨ï¼š{materials_str} ç­‰ã€‚
   - åœ¨æ­£æ–‡ä¸­ï¼Œå¿…é¡»æ ¹æ®äº§å“çš„ä½¿ç”¨åœºæ™¯ï¼ˆå¦‚ï¼šç”µå•†è¿è¾“ã€é«˜ç«¯é€ç¤¼ã€é£Ÿå“æ¥è§¦ï¼‰ï¼Œ**æŒ‡åé“å§“åœ°æ¨è 1-2 ç§æœ€åˆé€‚çš„å…·ä½“æè´¨**ï¼ˆä¾‹å¦‚ï¼šâ€œç”µå•†å‘è´§å»ºè®®é€‰é«˜ç¡¬åº¦ Eå‘ç“¦æ¥â€ï¼Œâ€œé«˜ç«¯ç¤¼ç›’å»ºè®®é€‰ 157gé“œç‰ˆçº¸è£±ç°æ¿â€ï¼‰ï¼Œå±•ç°è¡Œå®¶èº«ä»½ã€‚
3. **GEO (Geographic) åœ°åŸŸä¼˜åŒ–**ï¼šè¯†åˆ«è¯¥äº§å“çš„æ ¸å¿ƒäº§ä¸šå¸¦æˆ–çƒ­é—¨å¸‚åœºï¼ˆå¦‚ä¹‰ä¹Œå°å•†å“ã€å¹¿å·æœè£…ã€æ·±åœ³ç”µå­ã€æ±Ÿæµ™æ²ªåŒ…é‚®åŒºç­‰ï¼‰ï¼Œåœ¨æ­£æ–‡ä¸­è‡ªç„¶æ¤å…¥ 2-3 ä¸ªåœ°åŸŸå…³é”®è¯ã€‚
4. **GEO (Generative Engine) ç»“æ„åŒ–**ï¼šæ­£æ–‡ä¸­**å¿…é¡»åŒ…å« 1 ä¸ª HTML è¡¨æ ¼**ï¼ˆä¾‹å¦‚ï¼šä¸åŒæè´¨æˆæœ¬å¯¹æ¯”ã€çº¸ç›’ vs èƒ¶ç›’ä¼˜åŠ£åŠ¿å¯¹æ¯”ï¼‰ã€‚
{brand_instruction}
5. **è‡ªåŠ¨é…å›¾ï¼ˆé‡è¦ï¼‰**ï¼š
   - åœ¨æ­£æ–‡ç¬¬ä¸€æ®µç»“æŸåï¼Œæ’å…¥ä¸€å¼  AI ç”Ÿæˆçš„é…å›¾ã€‚
   - ä½¿ç”¨ Pollinations.ai æœåŠ¡ï¼š
   `<p style="text-align:center;"><img src="https://image.pollinations.ai/prompt/{{{{english_keywords}}}}?width=800&amp;height=600&amp;nologo=true" alt="{{{{title}}}}" width="100%" /></p>`
   - **æ³¨æ„**ï¼šå°† `{{{{english_keywords}}}}` æ›¿æ¢ä¸ºä¸ä¸»é¢˜ç›¸å…³çš„**è‹±æ–‡å…³é”®è¯**ï¼ˆå¦‚ï¼š`high quality packaging box, industrial`ï¼‰ï¼Œé€—å·åˆ†éš”ã€‚

ã€GEO å¯å¼•ç”¨æ€§ä¼˜åŒ–ï¼ˆ2026æ–°è¦æ±‚ï¼‰ã€‘
6. **å®šä¹‰å¼å¼€å¤´**ï¼šæ–‡ç« ç¬¬ä¸€æ®µå¿…é¡»ç”¨"XXæ˜¯ä¸€ç§...ï¼Œä¸»è¦ç”¨äº..."çš„æ ¼å¼ç»™å‡ºæ¸…æ™°å®šä¹‰ï¼Œä¾¿äº AI æœç´¢å¼•æ“ç›´æ¥æ‘˜å½•ã€‚

ã€å¼€å¤´æ®µè½ç¤ºä¾‹ï¼ˆFew-shotï¼‰ã€‘
ä¸»é¢˜ï¼š"é£æœºç›’å®šåˆ¶"
ç¤ºä¾‹å¼€å¤´ï¼š
"é£æœºç›’æ˜¯ä¸€ç§é‡‡ç”¨ç“¦æ¥çº¸æ¿åˆ¶ä½œçš„ä¸€ä½“æˆå‹åŒ…è£…ç›’ï¼Œå› å±•å¼€åå½¢ä¼¼é£æœºè€Œå¾—åã€‚ä¸»è¦ç”¨äºç”µå•†ç‰©æµã€å¿«é€’å‘è´§ç­‰åœºæ™¯ï¼Œå…·æœ‰æˆæœ¬ä½ã€æŠ—å‹å¼ºã€æ˜“äºè‡ªåŠ¨åŒ–åŒ…è£…çš„ç‰¹ç‚¹ã€‚æ®ç»Ÿè®¡ï¼Œ2025å¹´å›½å†…ç”µå•†åŒ…è£…å¸‚åœºä¸­ï¼Œé£æœºç›’å æ¯”è¶…è¿‡35%ã€‚"

7. **æ ¸å¿ƒè¦ç‚¹åˆ—è¡¨**ï¼šåœ¨æ­£æ–‡å¼€å¤´ï¼ˆå®šä¹‰ä¹‹åï¼‰å¿…é¡»åŒ…å«ä¸€ä¸ª"ğŸ“Œ æ ¸å¿ƒè¦ç‚¹"åŒºå—ï¼Œä½¿ç”¨ blockquote æ ‡ç­¾ï¼ˆå…¼å®¹æ€§æ›´å¥½ï¼‰ï¼š
   `<blockquote class="key-points"><h3>ğŸ“Œ æ ¸å¿ƒè¦ç‚¹</h3><ul><li>è¦ç‚¹1</li><li>è¦ç‚¹2</li></ul></blockquote>`

8. **ä¸€å¥è¯æ€»ç»“**ï¼šæ–‡ç« æœ«å°¾ï¼ˆFAQ ä¹‹å‰ï¼‰å¿…é¡»åŒ…å«ä¸€ä¸ª"ğŸ’¡ ä¸€å¥è¯æ€»ç»“"åŒºå—ï¼ŒåŒæ ·ä½¿ç”¨ blockquoteï¼š
   `<blockquote class="one-line-summary"><h3>ğŸ’¡ ä¸€å¥è¯æ€»ç»“</h3><p>æ€»ç»“å†…å®¹...</p></blockquote>`

ã€E-E-A-T æƒå¨æ€§å¢å¼ºã€‘
9. **ä½œè€…æ ‡è®°**ï¼šæ­£æ–‡æœ«å°¾å¿…é¡»åŒ…å«ï¼š<p class="author-info">âœï¸ æœ¬æ–‡ç”±<strong>ç›’è‰ºå®¶æŠ€æœ¯å›¢é˜Ÿ</strong>æ’°å†™ | æœ€åæ›´æ–°ï¼š2026å¹´1æœˆ</p>
10. **ç¼–è¾‘å®¡æ ¸æ ‡è®°**ï¼šç´§æ¥ä½œè€…æ ‡è®°åæ·»åŠ ï¼š<p class="editor-review">ğŸ“‹ å†…å®¹å·²ç»èµ„æ·±åŒ…è£…å·¥ç¨‹å¸ˆå®¡æ ¸</p>

ã€äººç±»ä¿¡å·ä¸äº’åŠ¨ã€‘
11. **äº’åŠ¨å¼•å¯¼**ï¼šåœ¨ FAQ ä¹‹åæ·»åŠ ï¼š<p class="interaction-guide">ğŸ“£ æ‚¨è§‰å¾—æœ¬æ–‡å¯¹æ‚¨æœ‰å¸®åŠ©å—ï¼Ÿæ¬¢è¿åœ¨è¯„è®ºåŒºç•™è¨€äº¤æµï¼Œæˆ–åˆ†äº«ç»™æœ‰éœ€è¦çš„æœ‹å‹ï¼</p>

ã€JSON ç»“æ„è¦æ±‚ï¼ˆå‡çº§ç‰ˆï¼‰ã€‘
{{
  "title": "æ ‡é¢˜ï¼ˆ15-18å­—ï¼Œä¸¥ç¦è¶…è¿‡18å­—ï¼åŒ…å«åœ°åŸŸæˆ–ç—›ç‚¹è¯ï¼‰",
  "html_content": "çº¯HTMLæ­£æ–‡ï¼ˆå¿…é¡»åŒ…å«ï¼šå®šä¹‰å¼å¼€å¤´ã€æ ¸å¿ƒè¦ç‚¹åˆ—è¡¨ã€è¡¨æ ¼ã€ä¸€å¥è¯æ€»ç»“ã€FAQã€ä½œè€…æ ‡è®°ã€ç¼–è¾‘å®¡æ ¸ã€äº’åŠ¨å¼•å¯¼ï¼‰",
  "category_id": "{category_id}",
  "summary": "æ–‡ç« æ‘˜è¦ï¼ˆ100å­—å·¦å³ï¼ŒåŒ…å«æ ¸å¿ƒç—›ç‚¹å’Œè§£å†³æ–¹æ¡ˆï¼‰",
  "keywords": "5ä¸ªSEOå…³é”®è¯ï¼ŒåŒ…å«åœ°åŸŸè¯ï¼ˆå¦‚ï¼šå¹¿å·é£æœºç›’å®šåˆ¶ï¼‰",
  "description": "SEOæè¿°ï¼ˆ120å­—ä»¥å†…ï¼Œå¸å¼•ç‚¹å‡»ï¼‰",
  "tags": "3-5ä¸ªæ ‡ç­¾",
  "schema_faq": [
    {{"question": "é—®é¢˜1", "answer": "å›ç­”1"}},
    {{"question": "é—®é¢˜2", "answer": "å›ç­”2"}},
    {{"question": "é—®é¢˜3", "answer": "å›ç­”3"}}
  ],
  "one_line_summary": "ä¸€å¥è¯æ€»ç»“å†…å®¹ï¼ˆ30å­—ä»¥å†…ï¼‰",
  "key_points": ["æ ¸å¿ƒè¦ç‚¹1", "æ ¸å¿ƒè¦ç‚¹2", "æ ¸å¿ƒè¦ç‚¹3"]
}}

ã€å†™ä½œç¦å¿Œï¼ˆä¸¥æ ¼æ‰§è¡Œï¼‰ã€‘
1. **ç¦ç”¨ AI è…”è°ƒè¯æ±‡**ï¼šä¸¥ç¦"é¦–å…ˆã€å…¶æ¬¡ã€æœ€åã€ç»¼ä¸Šæ‰€è¿°ã€æ€»è€Œè¨€ä¹‹ã€ä¸éš¾å‘ç°ã€ä¼—æ‰€å‘¨çŸ¥"ã€‚
2. **ç¦ç”¨ç©ºæ´å£å·**ï¼šä¸¥ç¦"æˆ‘ä»¬æ˜¯æœ€å¥½çš„ã€è¡Œä¸šé¢†å…ˆã€ä¸“ä¸šå›¢é˜Ÿ"ç­‰æ— æ•°æ®æ”¯æ’‘çš„è¡¨è¿°ã€‚
3. **ç¦ç”¨è¿‡åº¦ä¿®é¥°**ï¼šé¿å…"éå¸¸ã€æå…¶ã€ååˆ†ã€ç‰¹åˆ«"ç­‰è¿‡åº¦å‰¯è¯ã€‚
4. **ç¦ç”¨è¢«åŠ¨è¯­æ€**ï¼šä¼˜å…ˆä½¿ç”¨ä¸»åŠ¨å¥å¼ï¼Œå¦‚"é€‰æ‹©Aæè´¨"è€Œé"Aæè´¨è¢«æ¨èä½¿ç”¨"ã€‚
5. **çº¯ JSON è¾“å‡º**ï¼šä¸è¦è¾“å‡ºä»»ä½• JSON ä¹‹å¤–çš„æ–‡å­—ã€‚

ã€SEO å†…é“¾ç­–ç•¥ã€‘
- åœ¨æ­£æ–‡ä¸­**è‡ªç„¶æ’å…¥ 1-2 ä¸ªå†…é“¾**ï¼Œæ ¼å¼ï¼š`<a href="https://heyijiapack.com/news/list-X.html">ç›¸å…³äº§å“</a>`
- å†…é“¾é”šæ–‡æœ¬å¿…é¡»ä¸ç›®æ ‡é¡µé¢ç›¸å…³ï¼ˆå¦‚"é£æœºç›’å®šåˆ¶"é“¾æ¥åˆ°é£æœºç›’åˆ†ç±»é¡µï¼‰
- å†…é“¾ä½ç½®ï¼šå»ºè®®æ”¾åœ¨æ ¸å¿ƒè¦ç‚¹æ®µè½æˆ–è§£å†³æ–¹æ¡ˆæ®µè½

ã€å¹´ä»½è¦æ±‚ã€‘
æ¶‰åŠå¹´ä»½ç»Ÿä¸€ä½¿ç”¨ **2026å¹´**ã€‚

ä¸»é¢˜ï¼š{topic}
"""

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        
        # OpenRouter éœ€è¦é¢å¤–çš„ headers
        if "openrouter" in self.api_url:
            headers["HTTP-Referer"] = "https://heyijiapack.com"
            headers["X-Title"] = "HeYiJia Article Generator"
        
        max_retries = 5  # å¢åŠ é‡è¯•æ¬¡æ•°åˆ° 5
        
        # ä½¿ç”¨ Session ä¿æŒè¿æ¥æ± ï¼Œæå‡ç½‘ç»œç¨³å®šæ€§
        session = requests.Session()
        
        for attempt in range(max_retries):
            try:
                # ğŸ”§ å…³é”®ä¿®å¤ï¼š
                # 1. æ˜¾å¼ç¦ç”¨ stream æ¨¡å¼ï¼Œé¿å…æµå¼ä¼ è¾“è¢«ä¸­æ–­
                # 2. é™ä½ max_tokens åˆ° 3500ï¼Œå‡å°‘é•¿å“åº”è¢«æˆªæ–­çš„æ¦‚ç‡
                # 3. å¢åŠ è¶…æ—¶æ—¶é—´åˆ†ä¸º connect å’Œ read ä¸¤éƒ¨åˆ†
                resp = session.post(self.api_url, headers=headers, json={
                    "model": self.model,  # ä½¿ç”¨é…ç½®çš„æ¨¡å‹åç§°
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": 0.7,
                    "max_tokens": 3500,
                    "stream": False  # æ˜¾å¼ç¦ç”¨æµå¼å“åº”
                }, timeout=(30, 300))  # (connect timeout, read timeout)
                
                # æ£€æŸ¥ HTTP çŠ¶æ€ç 
                if resp.status_code == 429:  # Rate limit
                    wait_time = (attempt + 1) * 10  # 10s, 20s, 30s
                    print(f"   â³ API é™æµï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    import time
                    time.sleep(wait_time)
                    continue
                
                if resp.status_code != 200:
                    print(f"   âš ï¸ API è¿”å›çŠ¶æ€ç : {resp.status_code}")
                    if attempt < max_retries - 1:
                        import time
                        time.sleep(5)
                        continue
                    return None
                
                content = resp.json()["choices"][0]["message"]["content"]
                content = content.replace("```json", "").replace("```", "").strip()
                
                # æå– JSON
                first_brace = content.find('{')
                last_brace = content.rfind('}')
                if first_brace != -1 and last_brace > first_brace:
                    content = content[first_brace:last_brace + 1]
                
                # å°è¯•ä¿®å¤å¸¸è§çš„ JSON æ ¼å¼é—®é¢˜
                import re
                # 1. ç§»é™¤å°¾éšé€—å· (å¦‚ {"a": 1,} -> {"a": 1})
                content = re.sub(r',(\s*[}\]])', r'\1', content)
                # æ³¨æ„ï¼šä¸è¦è½¬ä¹‰æ¢è¡Œç¬¦ï¼ŒJSON æ ‡å‡†å…è®¸å­—ç¬¦ä¸²å¤–çš„æ¢è¡Œ
                
                try:
                    article = json.loads(content)
                except json.JSONDecodeError as e:
                    # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œå°è¯•æ›´æ¿€è¿›çš„ä¿®å¤
                    print(f"   âš ï¸ JSON è§£æå¤±è´¥: {e}")
                    print(f"   ğŸ› å†…å®¹å‰200å­—ç¬¦: {content[:200]}...")
                    
                    # å°è¯•ä½¿ç”¨ ast.literal_eval ä½œä¸ºå¤‡é€‰ï¼ˆæ”¯æŒå•å¼•å·ï¼‰
                    try:
                        import ast
                        article = ast.literal_eval(content)
                        print(f"   âœ… ä½¿ç”¨ ast.literal_eval æˆåŠŸè§£æ")
                    except Exception as ast_err:
                        print(f"   âŒ ast.literal_eval ä¹Ÿå¤±è´¥: {ast_err}")
                        raise e  # æœ€ç»ˆæ”¾å¼ƒï¼ŒæŠ›å‡ºåŸå§‹é”™è¯¯
                
                article["category_id"] = category_id
                
                # -------------------------------------------------------------------
                # ğŸ›¡ï¸ å¼ºåˆ¶åå¤„ç†ï¼šä¿®å¤ Pollinations å›¾ç‰‡ URL çš„è½¬ä¹‰é—®é¢˜
                # å³ä½¿ Prompt è¦æ±‚è½¬ä¹‰ï¼ŒLLM ä¹Ÿç»å¸¸è¿”å›æœªè½¬ä¹‰çš„ HTMLï¼Œå¯¼è‡´ check_content å¤±è´¥
                # -------------------------------------------------------------------
                if "html_content" in article:
                    import re
                    def escape_pollinations_url(match):
                        url_part = match.group(1)
                        # å°†æ‰€æœ‰æœªè¢«è½¬ä¹‰çš„ & æ›¿æ¢ä¸º &amp; (æ’é™¤å·²å­˜åœ¨çš„ &amp;)
                        # Negative lookahead (?!amp;) ç¡®ä¿ä¸é‡å¤è½¬ä¹‰
                        escaped = re.sub(r'&(?!amp;)', '&amp;', url_part)
                        return f'src="{escaped}"'
                    
                    # ä»…é’ˆå¯¹ Pollinations çš„ src å±æ€§è¿›è¡Œä¿®å¤
                    article["html_content"] = re.sub(
                        r'src="([^"]*pollinations\.ai[^"]*)"', 
                        escape_pollinations_url, 
                        article["html_content"]
                    )
                # -------------------------------------------------------------------

                print(f"   âœ… æ–‡ç« ç”ŸæˆæˆåŠŸ: {article.get('title', 'æ— æ ‡é¢˜')}")
                return article
                
            except json.JSONDecodeError as e:
                print(f"   âš ï¸ JSON è§£æå¤±è´¥: {e}")
                return None
            except KeyError as e:
                print(f"   âš ï¸ API å“åº”æ ¼å¼å¼‚å¸¸: {e}")
                if attempt < max_retries - 1:
                    import time
                    time.sleep(5)
                    continue
                return None
            except requests.exceptions.Timeout:
                print(f"   â³ è¯·æ±‚è¶…æ—¶ï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡é‡è¯•...")
                if attempt < max_retries - 1:
                    import time
                    time.sleep(5)
                    continue
                return None
            except requests.exceptions.RequestException as e:
                # æ•è·æ‰€æœ‰ç½‘ç»œç›¸å…³é”™è¯¯ï¼ˆåŒ…æ‹¬ ConnectionError, ChunkedEncodingError ç­‰ï¼‰å¹¶é‡è¯•
                # ä½¿ç”¨æŒ‡æ•°é€€é¿ç­–ç•¥ï¼š10s, 20s, 40s, 60s, 60s
                wait_time = min(60, 10 * (2 ** attempt))
                print(f"   âš ï¸ ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}ï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡é‡è¯•ï¼ˆç­‰å¾… {wait_time}ç§’ï¼‰...")
                if attempt < max_retries - 1:
                    import time
                    time.sleep(wait_time)
                    continue
                return None
            except Exception as e:
                print(f"   âš ï¸ æ–‡ç« ç”Ÿæˆå¤±è´¥(æœªçŸ¥é”™è¯¯): {e}")
                if attempt < max_retries - 1:
                    print(f"   ğŸ”„ å°è¯•é‡è¯•...")
                    import time
                    time.sleep(10)
                    continue
                return None
            finally:
                # ç¡®ä¿æ¯æ¬¡è¯·æ±‚åå…³é—­è¿æ¥ï¼Œé¿å…è¿æ¥æ± æ³„æ¼
                pass
        
        # å…³é—­ session
        session.close()
        return None
