import sys
import os
import requests
import time
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from shared.google_client import GoogleSheetClient
from shared import config
from step4_social.xhs_generator import XHSGenerator

def run():
    print("ğŸš€ å¼€å§‹é‡æ–°ç”Ÿæˆç¬”è®°å†…å®¹ (Regenerate)...")
    client = GoogleSheetClient()
    generator = XHSGenerator()
    
    # 1. å…ˆè·å–ä¸»è¡¨åŸæ–‡ (æ­¤æ—¶ client.table_id æ˜¯ Main Table)
    print("ğŸ” æ‰«æä¸»è¡¨åŸæ–‡...")
    main_records = client.fetch_records_by_status(status=config.STATUS_PUBLISHED, limit=500)
    title_to_content = {}
    for r in main_records:
        title = r.get("title", "").strip()
        content = r.get("html_content", "")
        if title and content:
            title_to_content[title] = content
    print(f"ğŸ“– ç´¢å¼•äº† {len(title_to_content)} ç¯‡æ–‡ç« å†…å®¹")

    # 2. åˆ‡æ¢åˆ° XHS è¡¨è·å–å¾…æ›´æ–°è®°å½•
    # ä¸´æ—¶è¦†ç›– table_id ä¸º XHS è¡¨
    client.table_id = config.FEISHU_XHS_TABLE_ID
    xhs_table_id = config.FEISHU_XHS_TABLE_ID
    
    print("ğŸ” æ‰«æ XHS è®°å½•...")
    url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{client.base_id}/tables/{xhs_table_id}/records/search"
    resp = requests.post(url, headers=client._headers(), json={"page_size": 500})
    
    if resp.json().get("code") != 0:
        print(f"âŒ Error: {resp.text}")
        return
    xhs_items = resp.json().get("data", {}).get("items", [])
    print(f"ğŸ“‹ æ‰¾åˆ° {len(xhs_items)} æ¡å¾…æ›´æ–°è®°å½•")
    
    updated_count = 0
    for item in xhs_items:
        fields = item['fields']
        rid = item['record_id']
        
        # è·å–æºæ ‡é¢˜
        source_title_obj = fields.get("Source", "")
        if isinstance(source_title_obj, list):
             source_title = source_title_obj[0]['text'] if source_title_obj else ""
        else:
             source_title = str(source_title_obj)
        
        source_title = source_title.strip()
        
        if not source_title:
            print(f"âš ï¸ è·³è¿‡ {rid}: Source å­—æ®µä¸ºç©º")
            continue
            
        if source_title not in title_to_content:
            print(f"âš ï¸ è·³è¿‡ {source_title}: ä¸»è¡¨æœªæ‰¾åˆ°å¯¹åº”åŸæ–‡")
            continue
            
        print(f"â™»ï¸ æ­£åœ¨é‡æ–°ç”Ÿæˆ: {source_title}")
        html_content = title_to_content[source_title]
        
        # è°ƒç”¨ç”Ÿæˆå™¨ (ä½¿ç”¨æ–°çš„ 900å­— Prompt)
        try:
            xhs_data = generator.generate_note(source_title, html_content)
            
            if xhs_data:
                # é‡æ–°ç»„åˆæ•°æ®ï¼Œä¿ç•™åŸæœ‰å°é¢å’Œæ—¶é—´ï¼Œåªæ›´æ–° Title, Content, Keywords
                
                # å…³é”®è¯æ ¼å¼åŒ–é€»è¾‘
                raw_keywords = xhs_data.get('keywords', '')
                formatted_keywords = ""
                # ... reuse format logic ...
                if isinstance(raw_keywords, list):
                    parts = raw_keywords
                else:
                    parts = str(raw_keywords).replace("ï¼Œ", ",").split(",")
                final_tags = []
                for p in parts:
                    tag = p.strip().lstrip("#")
                    if tag: final_tags.append(f"#{tag}")
                formatted_keywords = " ".join(final_tags)
                
                # æ›´æ–°
                update_fields = {
                    "Title": xhs_data['title'],
                    "Content": xhs_data['content'] + f"\n\n[å°é¢å›¾]: {fields.get('Cover', '')}", # ä¿ç•™åŸæ¥çš„å°é¢é“¾æ¥é€»è¾‘ (å¦‚æœCoverå­—æ®µè¯»å‡ºæ¥æ˜¯string)
                    # æ³¨æ„: å¦‚æœé£ä¹¦é‡Œ Cover æ˜¯é™„ä»¶ï¼Œfields.get('Cover') è¿”å›çš„æ˜¯ list[dict]ã€‚
                    # æˆ‘ä»¬ä¹‹å‰å†™å…¥çš„æ˜¯ URL string åˆ° Coverå­—æ®µã€‚
                    # å¦‚æœç”¨æˆ·æ²¡æ”¹å­—æ®µç±»å‹ï¼Œè¿™é‡Œè¯»å‡ºæ¥åº”è¯¥æ˜¯ List?
                    # ç¨³å¦¥èµ·è§ï¼Œæˆ‘ä»¬ä¸æŠŠå°é¢é“¾æ¥æ‹¼æ¥åˆ°contenté‡Œäº†ï¼Ÿæˆ–è€…åªæ‹¼æ–°çš„ï¼Ÿ
                    # ä¹‹å‰çš„ runner é€»è¾‘æ˜¯: Content + \n\n[å°é¢å›¾]: URL
                    # å¦‚æœæˆ‘ä»¬é‡æ–°ç”Ÿæˆ Contentï¼Œå°é¢å›¾ URL ä¼šä¸¢å¤± (å¦‚æœåœ¨Contenté‡Œ)ã€‚
                    # æˆ‘ä»¬éœ€è¦ä» fields é‡ŒæŠŠå°é¢å›¾ URL æ‰¾å›æ¥ã€‚
                    # å‡è®¾ Cover å­—æ®µå­˜çš„æ˜¯ URL stringã€‚
                    
                    "Keywords": formatted_keywords
                }
                
                # å°è¯•ä¿®å¤å°é¢å›¾é“¾æ¥ä¸¢å¤±é—®é¢˜:
                # è·å–æ—§å°é¢å›¾ URL
                old_cover = fields.get("Cover", "")
                cover_url_str = ""
                if isinstance(old_cover, list): # Attachment object
                    if old_cover: cover_url_str = old_cover[0].get("url", "")
                elif isinstance(old_cover, str):
                    cover_url_str = old_cover
                
                # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯•ä»æ—§ Content é‡Œæ­£åˆ™æå–? å¤ªå¤æ‚ã€‚
                # å‡è®¾ generator.generate_cover_image ä¸éœ€è¦é‡æ–°è·‘ (çœé’±/çœæ—¶é—´)
                # ç›´æ¥æ‹¼æ¥
                if cover_url_str and cover_url_str.startswith("http"):
                    update_fields["Content"] = xhs_data['content'] + f"\n\n[å°é¢å›¾]: {cover_url_str}"
                else:
                    # å¦‚æœæ²¡æœ‰å°é¢å›¾ï¼Œå¯èƒ½éœ€è¦é‡æ–°ç”Ÿæˆ? 
                    # æš‚æ—¶ä¿æŒ Content åŸæ ·
                    update_fields["Content"] = xhs_data['content']

                client.update_record(rid, update_fields)
                print(f"   âœ… å·²æ›´æ–°")
                updated_count += 1
                time.sleep(1) # é™é€Ÿ
                
        except Exception as e:
            print(f"   âŒ ç”Ÿæˆå¤±è´¥: {e}")

    print(f"ğŸ‰ å…¨éƒ¨å®Œæˆ: æ›´æ–°äº† {updated_count} æ¡è®°å½•")

if __name__ == "__main__":
    run()
